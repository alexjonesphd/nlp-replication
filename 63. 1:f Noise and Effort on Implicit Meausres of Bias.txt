Journal of Personality and Social Psychology
2008, Vol. 94, No. 1, 48 –59

Copyright 2008 by the American Psychological Association
0022-3514/08/$12.00 DOI: 10.1037/0022-3514.94.1.48

1/f Noise and Effort on Implicit Measures of Bias
Joshua Correll

This document is copyrighted by the American Psychological Association or one of its allied publishers.
This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.

University of Chicago
Phenomena that vary over time can often be represented as a complex waveform. Fourier analysis
decomposes this complex wave into a set of sinusoidal component waves. In some phenomena, the
amplitude of these waves varies in inverse relation to frequency. This pattern has been called 1/f noise
and, unlike white noise, it reflects nonrandom variation. Latencies in simple computer tasks typically
reveal 1/f noise, but the magnitude of the noise decreases as tasks become more challenging. The current
work hypothesizes a correspondence between 1/f noise and effort, leading to the prediction that
increasing effort will reduce 1/f noise. In 2 studies, the author examined the relationship between an
individual’s attempts to avoid bias (measured in Study 1, manipulated in Study 2) and 1/f noise in implicit
measures of stereotyping and prejudice. In each study, participants who made an effort to modulate the
use of racial information showed less 1/f noise than did participants who made less effort. The potential
value of this analytic approach to social psychology is discussed.
Keywords: 1/f noise, effort, stereotyping, prejudice

implementation of Fazio et al.’s (1995) task might pair each of 5
Black and 5 White faces with 10 positive target words and 10
negative target words, yielding 200 trials over the entire study. The
rationale for such high numbers is simple. A participant’s responses on any single trial are subject to several influences. One
influence should, at least in theory, be the participant’s general
evaluation of Whites and Blacks. To the extent that the participant
reacts more negatively to Blacks than to Whites, a Black prime
should facilitate responses to negative words and a White prime
should facilitate reactions to positive words. But on any given trial,
the effect of the psychological response in which the experimenter
is interested is presumably quite small. It may be overwhelmed by
other, less theoretically interesting sources of variance. The participant may blink at the moment the prime appears, or the particular face or target word presented may conjure up idiosyncratic
associations (e.g., “She looks like my roommate”). If the task
includes a sufficient number of trials and a sufficient variety of
stimuli, these extraneous influences should cancel each other out
and produce only a negligible effect. Averaging across all instances of a given trial type (e.g., all trials on which a Black face
precedes a positive word) minimizes the influence of unintended
variables, revealing the one factor that systematically influences
responses on every trial: the participant’s attitudes toward Whites
and Blacks.
Aggregation, however, sacrifices a great deal of information
about trial-by-trial variation in response times. Researchers generally assume that residual variability in the latencies (after accounting for the particular condition on each trial) is random and
meaningless. Given that assumption, the sacrifice seems acceptable because a variable that fluctuates randomly cannot convey
information. But what if residuals vary in a nonrandom fashion?
Just as systematic differences in the average response times to
Black and White faces can inform researchers about implicit bias,
systematic differences in patterns of variability in those responses
may hold important clues about the psychological states of the
participants (e.g., the diffusion model; Ratcliff, Van Zandt, &

Recent decades have witnessed dramatic changes in the study of
stereotyping and prejudice. As egalitarianism gained prominence
in the United States (Devine & Elliot, 1995), psychologists responded by developing ever more delicate measures to assess bias.
Initially, researchers simply replaced direct questions about intergroup attitudes with more subtly phrased, indirect questions about
racially or ethnically sensitive issues (e.g., McConahay, Hardee, &
Batts, 1981), but, more recently, computer-based measures have
proliferated. These computer tasks are usually designed to be
difficult or impossible to strategically control. For example, an
evaluative priming task, developed by Fazio and his colleagues
(Fazio, Jackson, Dunton, & Williams, 1995), primes participants
with either a Black face or a White face before asking them to
classify a target word as good or bad. Participants typically classify
positively valenced words (e.g., flower, rainbow) more quickly
after seeing a White face than after a Black face, but they classify
negative words (e.g., cockroach, death) more quickly after seeing
a Black face than after a White face. Other prominent measures
include the Implicit Association Test (IAT; Greenwald, McGhee,
& Schwartz, 1998), the Lexical Decision Task (Wittenbrink, Judd,
& Park, 1997), and the Go/No-Go Association Task (Nosek &
Banaji, 2001).
A common feature of many computer tasks is that they require
numerous responses. A typical paradigm involves something on
the order of 100 trials, each requiring a separate reaction. An

This material is based on work supported by National Institute of Mental
Health Grant F31-MH069017. I thank Gregory D. Webster for his thoughtful contributions to this work, the University of Chicago social program
and Bernd Wittenbrink for helpful critiques of drafts of this article, Lewis
O. Harvey for introducing me to “the next big thing” in the first place, and
the scientific tin-world model pioneer.
Correspondence concerning this article should be addressed to Joshua
Correll, Department of Psychology, University of Chicago, 5848 South
University Avenue, Green 415, Chicago, IL 60637. E-mail:
jcorrell@uchicago.edu
48

This document is copyrighted by the American Psychological Association or one of its allied publishers.
This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.

1/f NOISE AND EFFORT ON IMPLICIT MEASURES

49

McKoon, 1999). In line with this possibility, in the current article,
I examine measures of implicit racial bias to test the possibilities
that (a) trial-to-trial fluctuations often vary in a nonrandom fashion
and (b) the pattern of variability depends on participants’ taskrelated effort. Although this research focuses on racial bias, the
essential point of this article applies to other areas of research. In
many areas of social psychology, variance that is treated as meaningless may contain valuable information. If so, analytic strategies
like those presented here may provide social psychologists with
additional techniques to investigate the phenomena that interest
them.
It is important to note that this article does not dispute the value
of aggregation as a means of isolating the influence of attitudes or
associations on implicit tasks. The thrust of the argument is simply
that researchers can glean additional, potentially valuable information by analyzing “error” variance rather than throwing it away.
What makes this approach important for researchers in the field of
social psychology is that it can be applied to the kinds of data that
are already being collected in laboratories around the world. It can
even be applied retroactively to existing data sets. With no additional equipment and no new measures, these data can be reharvested, allowing researchers to potentially gain new insight into
human behavior. The strategy used here is based on work investigating 1/f noise.

1/f Noise and Response Times
1/f noise refers to nonrandom variation over space or time. 1/f
noise is intriguing in part because it seems to characterize a wide
range of phenomena, from variation in the magnitude of earthquakes and the intensity of pulsar emissions to fluctuations in the
auditory frequency of music. Each of these phenomena can be
represented as a complex waveform (e.g., the notes weaving up
and down as one reads a sheet of music). In similar fashion, in the
present work, I examine the fluctuations in response latency that
occur from one trial to the next as a participant performs a
computer task (see the top panel of Figure 1). This work draws on
research by Gilden (2001) and others, which tests for 1/f noise in
a trial series—treating the trial-by-trial variations in residualized
latency data as a wave.
1/f noise is examined by applying a fast Fourier transform (FFT)
to the complicated wave of latency data, decomposing it into
several pure sinusoidal waves (see the middle panel of Figure 1).
Adding these component waves back together reproduces the
original wave. Component waves can vary in terms of their frequency and power (a function of the wave’s amplitude), and one
can plot the power of each component wave against its frequency—after log transforming both variables—to examine the
relationship between them. This scatter plot is called a power
spectral density (PSD) chart (see the bottom panel of Figure 1).
If trial-by-trial variations are random (i.e., if the residual on trial
Xn is independent of the residual on trial Xn⫹k), the PSD should
show white noise: The power and frequency of the component
waves should not covary in any systematic fashion (after all, the
wave is random). On average, a random trial series therefore yields
a PSD in which the slope between power and frequency does not
differ from zero. 1/f phenomena, by contrast, produce a PSD with
a negative slope: Lower frequency waves have more power than
do higher frequency waves. That is, the power of a component

Figure 1. Simulated reaction time data (top panel), Fourier decomposition of reaction time data into component waves (middle panel), and power
spectral density graph showing a scatterplot of the power and frequency of
each component wave (bottom panel).

wave is proportional to the inverse of its frequency, or power ⬀
(1/frequency). This relationship is the origin of the term 1/f noise.
The pattern is also called 1/f␣ noise, where ␣ designates the slope
of the power–frequency relationship, or pink noise because the
PSD of the color pink similarly reveals that lower frequencies have
greater power.
Research in cognitive psychology has demonstrated that individuals performing simple tasks (e.g., determining whether a
target is present vs. absent, pressing a button at regular intervals) show 1/f noise in their responses. That is, after the effects
of any independent variables under investigation are partialed
out, a PSD of the residual latencies reveals the characteristic
negative slope of 1/f noise. This pattern is strongest or most
negative at lower frequencies and tends to flatten as frequency
increases. Gilden (2001; Gilden, Thornton, & Mallon, 1995;
Thornton & Gilden, 2005) has proposed a dual-component
model of 1/f noise in cognition. According to this model, 1/f
variation (which may reflect cognitive functioning) is masked at
high frequencies because of truly random variation or white
noise from other sources. Gilden attributed this high-frequency
noise to muscle activity. Figure 2 (left panel) shows a fairly
typical PSD for a participant performing a response-latency

This document is copyrighted by the American Psychological Association or one of its allied publishers.
This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.

50

CORRELL

Figure 2. Power spectral density (PSD) graphs for latency data for Participant A, who reported minimal effort
to avoid bias (left panel); for Participant A, again, after reshuffling the data to destroy the temporal sequence
(center panel); and for Participant B who reported high effort to avoid bias (right panel), Study 1. Black data
points represent log frequencies below 0, which were used to calculate the 1/f slope; gray points represent
high-frequency waves, which were excluded from the 1/f analysis.

task. The negative slope suggests 1/f noise. It is important to
note that these patterns are inherently a function of the temporal
order of the data series. Compromising that order eliminates the
1/f noise pattern. For example, if the residual data that produced
Figure 2’s left panel are shuffled randomly, a Fourier analysis
yields a flat, white PSD (see Figure 2, center panel).
The source of 1/f noise in reaction times is something of a
puzzle— one that is beyond the scope of the current article. The
following discussion merely attempts to give a rough overview
of some of the important issues. In an influential review, Gilden
(2001) referred to 1/f noise as a “carrier signal” (p. 55) for the
working mind. This is an intriguing and provocative statement,
but it leaves the genesis and meaning of the phenomenon
unclear. Van Orden and his colleagues (Van Orden & Holden,
2002; Van Orden, Holden, & Turvey, 2003) have observed that
1/f noise emerges from dynamic systems operating on the verge
of chaos (Bak, 1990). Partly on the basis of this correspondence, they argued that 1/f noise in response times stems from
self-organized criticality in the brain itself. Usher has tested
neural network models, which offer oblique support for this
possibility (Usher, Stemmler, & Olami, 1995, cited in Ward,
2002). When these networks are calibrated to behave in a
manner consistent with real neurons (i.e., exhibiting priming
effects at the level of individual neurons), two critical elements
emerge: The system’s activation fluctuates chaotically and the
individual artificial neurons emit 1/f noise. Van Orden ultimately suggested that if the brain functions in a self-organized,
verge-of-chaos fashion, psychologists may need to reconsider
the basic assumptions of their science. He argued that selforganization implies bidirectional causal influences. Goals and
efforts, which are presumed to generate or cause behavior, must
also be seen as consequences of the actions to which they give
rise. It is important to note, however, that this position is
contested (Wagenmakers, Farrell, & Ratcliff, 2004, 2005). Al-

though the existence of 1/f noise is superficially consistent with
chaotic phenomena, it may also stem from purely nonchaotic
processes. For example, autocorrelation can produce 1/f-like
patterns if the correlations exist at several time lags and those
lags span several orders of magnitude (Ward, 2002). Wagenmakers argued that 1/f noise need not imply chaos and that the
pattern can be explained through mechanisms like fluctuations
in attention or the aggregation of several sources of short-term
serial dependence. For the purposes of the current research, it is
not especially important whether 1/f-like patterns stem from
nonlinear, chaotic processes (long-range dependencies) or simpler, short-range dependencies. The point of this research is
simply to test whether such 1/f patterning characterizes data
from implicit measures in social cognition and to test the degree
to which those patterns vary as a function of task-relevant
effort.

1/f Noise and Task Difficulty
The various possible sources of 1/f noise (e.g., chaotic,
self-organizing processes in the brain or the cumulative input of
various short-term dependencies) raise the possibility that 1/f
noise may be sensitive to more familiar processes like attention
and cognitive effort. It is notable that 1/f noise seems to depend
on the nature of the task that participants are asked to perform.
In simple cognitive tasks (e.g., detecting a right-to-left gradient), a robust 1/f pattern is usually obtained. But in more
difficult paradigms (e.g., with more response options, when a
simple task is complicated by high memory load), the signature
slope of 1/f noise weakens (Clayton & Frey, 1997; Ward &
Richard, 2001, as cited in Ward, 2002). Clayton and Frey asked
participants to perform one of three tasks. The easiest involved
pressing one button if the stimulus on a given trial was an X and
another button if the stimulus was an O. More difficult tasks

This document is copyrighted by the American Psychological Association or one of its allied publishers.
This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.

1/f NOISE AND EFFORT ON IMPLICIT MEASURES

involved indicating whether the stimulus on the current trial
was identical to the stimulus on the previous trial (a one-back
task) or—in the most difficult condition—indicating whether
the current stimulus matched the stimulus two trials earlier (a
two-back task). 1/f noise was clearly evident in the easiest
condition, but on the more difficult tasks, the negative relationship between power and frequency flattened dramatically. A
task’s difficulty, in other words, moderated the emission of 1/f
noise. PSDs for simple tasks reveal more negative, steeper,
pinker slopes, whereas PSDs for complex tasks produce more
positive, flatter, whiter slopes.
Whereas extant work has examined variation in 1/f noise as a
function of the nature of the task a participant performs, the current
research explores a different question. In this article, I test the
possibility that even when participants perform an identical task,
differences in the way they approach that task will affect the
expression of 1/f noise. In tasks related to prejudice and stereotyping, there is reason to expect that some individuals will exert
more effort than others. Some participants express strong motivation to avoid prejudiced behavior for a variety of reasons, and this
motivation significantly alters their performance on both explicit
questionnaire measures and implicit measures of racial bias (Devine, Plant, Amodio, Harmon-Jones, & Vance, 2002; Dunton &
Fazio, 1997; Plant & Devine, 1998). More recently, Glaser and
Knowles (in press) have measured implicit motivation to control
prejudice. Someone who is high in this motivation should strive to
appear— or even to be— egalitarian. Someone who is low in this
motivation typically worries less about the potentially racist implications of his or her behavior.
In the current studies, I hypothesized that a participant’s effort
on a given task will affect the way they approach implicit measures
of racial bias, even if those measures were designed to be impervious to strategic control (Fazio et al., 1995). Highly motivated
participants should attempt to control their behavior (Monteith,
1993; Richeson & Trawalter, 2005), and their desire to avoid bias
should prompt increased cognitive effort. In line with the effects
reported by Clayton and Frey (1997) and Ward and Richard (2001,
as cited in Ward, 2002), it was predicted that effort would reduce
the prevalence of 1/f noise. If this hypothesis is correct, high effort
should be associated with more positive PSD slopes, and low effort
should be associated with more negative slopes.
This hypothesis was tested in two studies. In Study 1, participants performed a video game task in which they made
shoot/don’t-shoot decisions for a series of armed and unarmed
targets who were either White or Black (Correll, Park, Judd, &
Wittenbrink, 2002). This task has been used to measure racial
bias. Participants subsequently reported (a) the extent to which
they had tried to avoid showing bias and (b) the perceived
difficulty of the task. In Study 2, a different task was used to
measure racial bias, and participants’ effort was experimentally
manipulated. Participants performed the computer task after
receiving explicit instructions either to use racial stereotypes or
to avoid using stereotypes or in the absence of any specific
instructions (the control condition). In both studies, participants
who exerted greater effort, either on their own or because they
were instructed to do so, were expected to demonstrate reductions in 1/f noise.

51
Study 1
Method

Participants and Design
Twenty-four White undergraduates participated in partial fulfillment of a course requirement. During the experimental session,
each participant performed a shoot/don’t-shoot video game task,
which presented Black and White targets who were either armed or
unarmed. The goal of this task was to shoot all armed targets but
to indicate don’t shoot for all unarmed targets. Participants also
completed a modified version of a Stroop (1935) task, described
below, which was included to allow the examination of discriminant validity. This second task helps determine whether results on
the video game are specific to that measure or, instead, emerge in
any reaction-time task. The results reported by Clayton and Frey
(1997) suggest that more challenging tasks reduce 1/f noise, but it
is not clear what drives this effect. Task-relevant effort and perceived task difficulty might both be associated with reductions in
1/f noise in the video game. On completion of both tasks, participants therefore reported the degree to which they tried to avoid
biased behavior in the video game task (rated effort) and the
degree to which the task was perceived as difficult (rated difficulty). The study followed a 2 (target race: Black vs. White) ⫻ 2
(object type: gun vs. nongun) within-participants design, with
rated effort and rated difficulty measured continuously as betweenparticipants factors.

Materials
Video game. This study used a simple video game task (for
details, see Correll et al., 2002). As implemented in Study 1, the
task consisted of 200 trials in which participants were asked to
respond to an image of a young man (i.e., a target). One hundred
trials presented a Black target; 100 trials presented a White target.
Within each race, half of the targets held pistols and half held
innocuous objects (e.g., cell phones or wallets). Fifty targets, then,
appeared in each of the four cells defined by the 2 ⫻ 2 repeatedmeasures design: unarmed White, unarmed Black, armed White,
armed Black. Participants were instructed to press a button labeled
shoot if the target was armed but to press a separate button labeled
don’t shoot for any unarmed targets. This task typically imposes a
response window of 850 ms, but to avoid missing data (which is
problematic for Fourier analysis), this response deadline was eliminated in the present study. A 500-ms intertrial interval preceded
each trial. A 16-trial practice round preceded the test phase.
Stroop task. The modified Stroop task involved a series of
trials on which a fixation cross (500 ms) appeared on the computer
screen, followed by a simple letter string (xxxx) in one of four
colors: red, green, blue, or yellow. Participants were asked to
categorize the color of the typeface by pressing one of four
color-designated keys. The task began with a 40-trial block of
practice trials after which participants were asked to contact the
experimenter if they had any questions. After the experimenter
addressed any questions, participants pressed the space bar to
resume the task, which started with 10 buffer trials prior to a
200-trial test block. A 1,000-ms intertrial interval preceded each
trial.

CORRELL

52

Questionnaire. After the computer tasks, participants completed a short questionnaire, which included questions assessing
demographics, measures of prejudice, and two critical questions.
The first question (rated effort) simply asked, with reference to the
video game task, “How hard did you try to avoid showing racial
bias?” Response options ranged from 1 (I didn’t try at all) to 9 (I
tried very hard). The second question (rated difficulty) also referred to the video game task: “How difficult was the task?”
Response options ranged from 1 (not at all difficult) to 9 (very
difficult).

This document is copyrighted by the American Psychological Association or one of its allied publishers.
This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.

Procedure
A White female research assistant met participants individually
and introduced the shoot/don’t-shoot and Stroop tasks as tests of
vigilance. After the tasks, participants completed the questionnaire. They were then thanked and debriefed.

Results and Discussion
Mean-Level Effects
Reaction times for correct trials on the video game task were log
transformed (data are reported in the original metric for ease of
comprehension). Log-transformed latencies were then averaged
separately for each of the four target types: unarmed White,
unarmed Black, armed White, armed Black. Similarly, error rates
were calculated for each trial type. These averages were submitted
to separate Target Race ⫻ Object Type repeated-measures analyses. In this paradigm, participants typically respond more slowly
and with a greater number of errors to targets that violate cultural
stereotypes (unarmed Blacks and armed Whites) and more quickly
and with fewer errors to targets that conform to those stereotypes
(armed Blacks and unarmed Whites). In line with prior work,
latencies from Study 1 revealed a pattern of bias, manifested as a
significant interaction between target race and object type, F(1,
23) ⫽ 13.91, p ⬍ .002. Participants shot armed Black targets (M ⫽
627 ms) more quickly than they shot armed Whites (M ⫽ 648 ms),
F(1, 23) ⫽ 5.38, p ⬍ .03, and they were faster to choose the don’t
shoot response when an unarmed target was White (M ⫽ 684 ms)
rather than Black (M ⫽ 705 ms), F(1, 23) ⫽ 14.06, p ⬍ .002. For
each participant, an index of bias was calculated, reflecting the
magnitude of the within-subject interaction (i.e., bias ⫽ [armed
White–armed Black] ⫹ [unarmed Black– unarmed White]).
In an analysis of error rates, the Target Race ⫻ Object Type
interaction was similar in direction but did not approach significance, F(1, 23) ⫽ 0.99, p ⬍ .34. This is likely a consequence of the
extended time window, which tends to reduce error rates (see
Correll et al., 2002).
A regression was performed for each participant to analyze 1/f
noise, modeling the log-transformed latency on a given trial as a
function of the target type (armed Black, armed White, unarmed
Black, unarmed White), accuracy (correct response vs. incorrect
response), and trial number. These regressions were designed to
remove known sources of variability from the reaction times. Trial
number was included to account for increases in speed over the
course of the task—a nonstationarity that can disrupt the Fourier
analysis. PSD was calculated for each participant using the Statistical Analysis Software SPECTRA procedure with a Tukey–

Hanning window (see Appendix for example syntax). With 200
trials, the FFT decomposed each trial series into 100 component
waves. The analysis thus provides estimates of the power and
frequency of 100 waves for each participant. The lowest estimable
frequency describes a wave with a single cycle over the course of
the task (f ⫽ 2␲ radians/200 trials ⫽ .031 radians/trial). The
highest estimable frequency (the Nyquist frequency) is half the
sampling rate, referring to a wave that cycles once every 2 trials
(f ⫽ 2␲ radians/2 trials ⫽ 3.142 radians/trial).
A visual inspection of the video game PSDs revealed a generally
flat slope at high frequencies. This pattern, suggestive of white
noise, conforms to Gilden’s dual-component model (2001; Gilden
et al., 1995), which argues that 1/f patterns emerge only at lower
frequencies. It is interesting that at lower frequencies, participants
seemed to vary dramatically. Some showed a relatively steep
slope; others showed a fairly flat slope (see Figure 2, left and right
panels, respectively).
A second within-subject regression was performed to quantify
the power–frequency relationship for each participant. The goal
was to estimate the relationship at low frequencies, but this effort
is complicated by the general prevalence of white noise at high
frequencies (Gilden, 2001). In essence, the power–frequency relationship is not a straight line; it has a kind of elbow. Clayton and
Frey (1997) addressed this nonlinear relationship by excluding
high-frequency data and estimating 1/f noise as the linear relationship for the component waves below the elbow. Accordingly, the
linear relationship between power and frequency was estimated for
log frequencies below zero. As discussed above, if the residual
latencies contain nothing but random error, the average slope
estimated by this regression should be flat (it should hover around
zero). Such a slope would indicate white noise. By contrast, 1/f
noise would produce a negative slope and a significant deviation
from zero. Across participants, the average linear slope was, indeed, significantly negative, mean slope ⫽ ⫺0.18, t(23) ⫽ ⫺2.21,
p ⬍ .04, suggesting that these residuals are not entirely random.
This test provides the first evidence of 1/f phenomena in social–
cognitive latency measures.

Correlational Analyses
My primary goal in Study 1 was to examine the relationship
between a participant’s PSD slope in the video game and (a)
efforts to avoid bias and/or (b) the perceived difficulty of the task.
Prior literature offers no real basis for an a priori prediction about
the distinction between rated effort and rated difficulty in this
study. Participants low in rated effort and participants low in rated
difficulty might both be expected to exhibit a more steeply negative 1/f slope, whereas those reporting high effort and those reporting high difficulty should produce a more positive, flatter
slope. Rated effort and rated difficulty were, somewhat surprisingly, unrelated, r(22) ⫽ .24, p ⬍ .24. They are therefore treated
separately below. The relationship between rated effort and 1/f
noise was tested by regressing participants’ slopes (derived from
the PSD analyses) on their explicit ratings of effort. The relationship was significant and positive, F(1, 22) ⫽ 6.33, p ⬍ .02 (see
Figure 3 and Table 1). This relationship remains significant when
controlling for task difficulty, F(1, 21) ⫽ 5.24, p ⬍ .04. PSD
slopes were then estimated for participants with high and low rated
effort. Participants reporting relatively low effort (1 standard de-

This document is copyrighted by the American Psychological Association or one of its allied publishers.
This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.

1/f NOISE AND EFFORT ON IMPLICIT MEASURES

Figure 3.
Study 1.

53

Power spectral density (PSD) slopes for participants plotted as a function of rated effort to avoid bias,

viation below the mean) showed clear evidence of 1/f noise. Their
simple linear slopes were negative and significantly different from
zero, mean slope ⫽ ⫺0.39, t(22) ⫽ ⫺3.51, p ⬍ .002. Participants
reporting greater effort (1 standard deviation above the mean)
showed less negative (more positive) slopes, which did not differ
significantly from zero, mean slope ⫽ ⫺0.02, t(22) ⫽ ⫺0.16, p ⬍
.88. This nonsignificant slope (white noise is, in essence, a null
effect) is not especially important in its own right. The critical
point of this analysis is that there is a significant relationship
between the questionnaire measure (self-reported effort to avoid
bias) and the expression of 1/f noise in this task. Higher effort is
associated with increasingly flat (relatively white) PSD slopes.
A similar regression offered no evidence that rated difficulty
was related to 1/f noise, F(1, 22) ⫽ 0.91, p ⬍ .35. Although these
data show no relationship, this study obviously does not provide a
conclusive test of the relationship between perceived difficulty and
1/f noise. It seems plausible that social desirability concerns affected participants’ willingness to report that a task (one with clear
implications for racial bias) was difficult for them. Because the
questionnaire followed both the video game and the Stroop task, it
is also certainly possible that participants understood the question
as referring to the entire study (both tasks) rather than just the
video game (see below).
It was predicted that the that residual latencies in Study 1’s
shoot/don’t-shoot task would show evidence of nonrandom trialto-trial variation consistent with 1/f noise. Further, the magnitude

of this noise was expected to covary with participants’ orientation
to the computer task. The PSD analyses showed clear evidence of
1/f noise, on average, and also revealed the anticipated relationship
between 1/f noise and participants’ self-reported attempts to avoid
bias during the course of the game. Participants who made little
effort showed a relatively steep PSD slope. Participants who put
forth greater effort showed a flatter slope.
The significance of these results is manifold. First, at the simplest level, they show that residual variance in a participant’s
response times during a computer-based measure of bias (variance
that is usually treated as meaningless error) is not completely
random. These findings add to the growing body of work on 1/f
noise by demonstrating the patterns in socially oriented responsetime tasks. In fact, to my knowledge, this is the first demonstration
of 1/f noise in implicit measures of stereotyping and, indeed, the
first demonstration in any kind of social psychological research.
Second, whereas Clayton and Frey (1997) showed that 1/f noise
varies as a function of participants’ task, the current work shows
that even when participants perform the identical task, the magnitude of 1/f noise depends on individual differences in effort. It is
critical to note that in the current work, all participants performed
exactly the same task. Variability in 1/f noise was due entirely to
differences in participants’ orientation to that task. This study
therefore extends understanding of the variables that can moderate
1/f noise but also holds out promise that spectral analysis can shed
light on phenomena important to social psychology.

Table 1
Means, Standard Deviations, and Correlations, Study 1
Variable
1.
2.
3.
4.
5.

Rated effort
Rated difficulty
Video game PSD slope
Bias in latencies (ms)
Stroop PSD slope

Note. PSD ⫽ power spectral density.
†
p ⬍ .10. * p ⬍ .05. ** p ⬍ .01.

M

SD

1

2

3.58**
3.16**
⫺0.18*
38.89**
⫺0.47**

2.59
1.95
0.40
42.74
0.34

—
.24
.47*
⫺.26
.06

—
.20
.15
.37†

3

—
⫺.05
.10

4

5

—
.26

—

54

CORRELL

This document is copyrighted by the American Psychological Association or one of its allied publishers.
This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.

Ancillary Analyses
A number of additional tests were conducted to clarify the
nature of these effects and rule out alternative interpretations. First,
one might imagine that the relationship between rated effort and
1/f noise emerges simply because high-effort participants respond
more slowly (or more quickly) than do low-effort participants. To
address this question, I regressed PSD slopes simultaneously on
both rated effort and average latencies from the video game. In this
analysis, mean latencies were marginally related to slope estimates, F(1, 21) ⫽ 3.06, p ⬍ .10, such that longer latencies were
associated with flatter slopes. Critically, however, the relationship
between effort and PSD slope remained significant when controlling for average reaction time, F(1, 21) ⫽ 6.15, p ⬍ .03. Slower
responding cannot account for these effects.
Second, as shown in Figure 2, randomly sorting Participant A’s
residuals prior to the Fourier analysis eliminated the pattern of 1/f
noise. All participants’ residuals were randomly sorted to provide
a slightly more rigorous test of the importance of serial order.
Next, both the average PSD slope in the video game task (across
all participants in the sample) as well as the correlation between
those individual slopes and rated effort were computed. This
process was repeated 25 times, yielding 25 estimates of the average slope and 25 estimates of the correlation between slope and
effort. When the temporal order of the trials was disrupted, the
average participants’ PSD slope across these 25 replications hovered around zero, mean slope ⫽ 0.009, SD ⫽ 0.053, t(24) ⫽ 0.88,
p ⬍ .39. Similarly, the average correlation between the slope (once
order had been disrupted) and rated effort did not differ from zero,
mean correlation ⫽ ⫺0.010, SD ⫽ 0.262, t(24) ⫽ ⫺0.19, p ⬍ .86.
These analyses suggest that the phenomenon in question is highly
dependent on the temporal order of trials. The primary results of
this study cannot be explained as an artifact of the distributions of
the latencies. They are not due to changes (as a function of effort)
in the mean, standard deviation, skewness, or kurtosis of the
latency data.
Third, in addition to the video game task, participants in this
study completed a modified version of the Stroop (1935) task. The
log-transformed latency data from the Stroop task were submitted
to a spectral analysis, similar to the video game analysis above,
and a PSD slope was calculated. On average, this slope was steeply
negative, mean slope ⫽ ⫺0.47, t(23) ⫽ ⫺6.92, p ⬍ .0001,
suggesting a strong pattern of 1/f noise. This task is useful in the
context of this study because it provides a test of the specificity of
the relationship between 1/f noise and rated effort, reported above.
Does this correlation reflect a general orientation on the part of the
participants or rather—as hypothesized—a task-specific orientation to a particular measure of racial bias? It is possible, for
example, that individual differences in 1/f noise, demonstrated in
the video game task, reflect stable differences between participants. Those who show less 1/f noise on one task may show less
1/f noise on any task. Conceivably, of course, such a reduction
could still be driven by effort, such that some participants exert
more effort on any task they perform. In either case, if the patterns
reported above reflect a general orientation to response-latency
tasks, one might expect (a) rated effort on the video game to
predict 1/f noise in the Stroop task and (b) 1/f noise in the video
game task to correlate with 1/f noise in the Stroop task. The
general-orientation account was tested by examining correlations

of PSD slopes from the Stroop task with rated effort and rated
difficulty (measures by which participants were supposed to assess
the video game task), PSD slopes from the video game task, and
bias in the video game task (see Table 1). Of critical importance,
rated effort to avoid racial bias did not predict the Stroop PSD, nor
were the PSD slopes from the video game related to those from the
Stroop task. Further, when PSD slopes from the video game were
regressed on rated effort while controlling for slopes in the Stroop
task, the critical relationship between rated effort and 1/f noise in
the video game task remained significant, F(1, 21) ⫽ 5.95,
p ⬍ .03.
Surprisingly, however, Stroop PSD slopes were marginally correlated with rated difficulty, r(22) ⫽ .38, p ⬍ .07. This unexpected
relationship raises an interesting, although admittedly post hoc,
possibility. When completing the difficulty ratings, participants
were asked to rate only the difficulty of the video game task. It
may be that the instructions were not sufficiently clear and that
participants inappropriately rated the overall difficulty of the session or, perhaps, the difficulty associated specifically with the
Stroop task. This tendency may have been exacerbated because the
initial question, on which participants rated their effort, focused on
attempts to avoid racial bias, which necessarily referred exclusively to the racially relevant video game. The question would
make no sense for the Stroop. Participants may then have expected
that the other question (on which participants rated task difficulty)
applied to the other task (the Stroop; e.g., Heibeck & Markman,
1987; Waxman & Klibanoff, 2000).
In any event, the primary findings of Study 1 provide support for
a relationship between task-relevant effort and 1/f noise. Selfreported effort to avoid bias uniquely predicted reductions in 1/f
noise in a task that was relevant to racial bias (the shoot/don’tshoot video game). This measure had no impact on 1/f noise in a
race-neutral Stroop task. Study 1, then, provides a correlational
demonstration of the relationship between 1/f noise and effort on a
single measure of racial bias. Study 2 was conducted to replicate
and extend these findings by using an experimental manipulation
to test the causal relationship between effort and 1/f noise.

Study 2
In Study 1, effort was measured using a questionnaire. The
correlation between participants’ self-reported effort and the PSD
patterns derived from their response times suggests that effort can
moderate 1/f noise. Study 2 sought to bolster this claim by experimentally manipulating participants’ effort on a separate computerbased measure of racial bias.
This research essentially strives to recreate a study conducted by
Payne and his colleagues (Payne et al., 2002), who asked participants to either accentuate or avoid the use of racial cues in a
weapon-identification paradigm. Like the shoot/don’t-shoot task in
Study 1, this task assesses racial bias in reactions to guns and
harmless objects. On a series of trials, participants were primed
with either a Black face or a White face. They were then asked to
identify a target image as either a gun or a tool. In their study,
Payne and his colleagues varied the instructions they gave to
participants. Participants in the control condition were simply
asked to perform the task to the best of their ability. A second
group was asked to perform the task but was specifically instructed
to avoid the use of race. They were not to allow the race of the

This document is copyrighted by the American Psychological Association or one of its allied publishers.
This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.

1/f NOISE AND EFFORT ON IMPLICIT MEASURES

prime to influence their judgments. A third group was explicitly
asked to make use of race during the performance of the task. They
were asked to behave like racial profilers. Payne found greater bias
in both experimental conditions. This finding makes perfect sense
for the participants who were instructed to act like profilers. They
were simply doing what they were told. But, ironically, the participants who were asked to avoid using the racial cues showed
increases in bias. Relative to controls, they showed stronger associations between Blacks and guns. The authors suggested that
because the instructions called attention to the race of the prime,
participants in the experimental conditions were more susceptible
to race-based associations (whether that influence was consistent
or inconsistent with their instructions).
In addition to demonstrating an interesting and counterintuitive
effect, Payne et al.’s (2002) study has clear implications for
task-relevant effort. Participants in the control condition approached the task without any experimentally imposed demands.
By contrast, participants in both the avoid-race and use-race conditions were asked to consciously control or modulate their performance. Whether or not their efforts were ultimately successful,
these participants approached the task with additional experimentally imposed demands. If 1/f noise is sensitive to increased effort,
spectral analysis should reveal differences between the relatively
minimal effort required of the control condition and the greater
effort required of the experimental conditions.

Method
Participants and Design
Seventy-one undergraduates participated in return for course
credit. All participants performed a simple task in which they were
asked to classify objects that appeared on a computer screen as
either guns or tools. Prior to the presentation of the target object,
however, participants were primed with either a Black or a White
face (Payne, 2001). Although all participants performed the same
task, individuals were randomly assigned to one of three conditions, each imposing a different task-relevant goal. Participants in
the control condition were given no specific instructions; participants in the avoid-race condition were instructed not to use racial
information when making their decisions; participants in the userace condition were instructed to let racial cues guide their behavior during the task. This study followed a 3 (instructions: control
vs. avoid race vs. use race) ⫻ 2 (prime race: Black vs. White) ⫻
2 (object type: gun vs. tool) mixed-model design, with repeated
measures on the last two factors.

Materials
The weapon-identification task was based on the paradigm
developed by Payne (2001, Study 1). The task consisted of a
25-trial practice phase followed by a test phase of 200 trials. Each
trial began with the presentation of a prime face (200 ms). Primes
consisted of black-and-white photographs (faces only) of five
Black men and five White men. Immediately after the prime, a
target object appeared (200 ms). Target stimuli consisted of blackand-white photographs of 5 guns and 5 power tools (drills, screwdrivers, etc). After 200 ms, the target image was replaced with a
mask (a random pattern of black and white rectangles), which

55

remained on screen until the participant responded. A 1,000-ms
intertrial interval preceded the onset of the next prime.
In the original study, Payne and his colleagues (2002) forced
participants to respond within 700 –1,200 ms after the onset of the
object image. They also presented the target object for only 100 ms
(rather than 200 ms, as in the present research). Payne et al.’s
parameters were presumably motivated by their interest in process
dissociation procedure estimates of control and automatic bias,
which are derived from patterns of errors (see also Payne, 2001,
Study 2). More restrictive time limits tend to increase the likelihood of errors in these tasks. By contrast, the current research
focuses on variance in reaction times, and forcing participants to
respond within a given time window carries with it the possibility
that participants will respond too slowly on some trials, resulting
in missing data, which (as noted above) are problematic for the
analysis. The test phase of Study 2 therefore imposed no response
deadline. To encourage participants to respond quickly, the practice phase imposed a deadline of 1,000 ms. Participants who
responded too slowly during the initial 25 trials received a message
to that effect. Fewer than 1% of responses exceeded 1,000 ms
during the test phase.

Procedure
A White male experimenter introduced the study as an investigation of vigilance. He seated participants in individual rooms,
each equipped with a computer. A randomly selected computer
program delivered the instructions, which constituted the experimental manipulation. These instructions were taken directly from
Payne et al. (2002).

Results and Discussion
Mean-Level Effects
In the weapon identification task, analyses of reaction times
were based on the log-transformed latencies from trials on which
participants had responded correctly. These values were averaged
for each of the four trial types (Black– gun, White– gun, Black–
tool, White–tool). Similarly, error rates were calculated for each
trial type. These averages were submitted to separate Prime
Race ⫻ Object Type repeated-measures analyses, which revealed
an interaction (i.e., bias) in participants’ errors, F(1, 70) ⫽ 10.05,
p ⬍ .003, and a nonsignificant interaction (similar in direction to
the error effects) in their latencies, F(1, 70) ⫽ 1.23, p ⬍ .30. The
error analysis suggests that participants were more likely to classify a tool as a weapon after a Black face (M ⫽ 2.66) than after a
White face (M ⫽ 2.44) but more likely to identify a gun as a tool
after a White face (M ⫽ 2.66) than after a Black face (M ⫽ 1.87).
These results are somewhat surprising given the lack of any
response deadline in this task. For subsequent analyses, two parallel indices were computed to reflect the Prime Race ⫻ Object
Type interactions for errors and, separately, for latencies. In both
cases, bias ⫽ (White– gun ⫺ Black– gun) ⫹ (Black–tool ⫺ White–
tool).
Analysis of 1/f noise was conducted as in Study 1. For each
participant, FFTs were applied to the residuals of the latencies
(after statistically removing effects of trial type, accuracy, and trial
number). The resulting estimates of power and frequency were log

CORRELL

56

transformed. The linear relationship between power and frequency
was assessed with a second within-subject regression, excluding
log frequencies greater than zero to eliminate the white noise at
higher frequencies. Averaging across participants, the average
slope of this relationship was negative, M ⫽ ⫺0.33, t(70) ⫽
⫺8.48, p ⬍ .001, indicative of 1/f noise.

This document is copyrighted by the American Psychological Association or one of its allied publishers.
This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.

Effects of Condition
Estimates of the slopes as well as estimates of bias in both the
errors and the latencies were then analyzed as a function of
condition. These analyses used two orthogonal codes. The first
(control ⫽ ⫺2, avoid race ⫽ ⫹1, use race ⫽ ⫹1) assessed
differences between the control condition and the two experimental conditions. The second (control ⫽ 0, avoid race ⫽ ⫺1, use
race ⫽ ⫹1) assessed differences between the avoid-race and
use-race conditions.
Study 2’s primary question involves the slopes derived from the
PSD estimates. As task-relevant effort increases, participants were
expected to exhibit flatter, more positive slopes. It was therefore
predicted that participants in the use-race and avoid-race conditions (conditions that imposed additional task demands) would
show more positive (less negative) PSD slopes. As predicted,
analysis revealed a significant difference between the control condition and the average of the two experimental conditions in terms
of the magnitude of the PSD slopes, F(1, 68) ⫽ 5.52, p ⬍ .02 (see
Table 2 and Figure 4). Pairwise comparisons showed that participants in both the avoid-race condition and the use-race condition
exhibited more positive slopes (suggesting greater effort) than did
participants in the control condition, Fs(1, 68) ⫽ 5.24, 3.17, ps ⬍
.03, .08, respectively, although the latter comparison was only
marginally significant. Participants in the avoid-race condition did
not differ from those in the use-race condition, F(1, 68) ⫽ 0.19,
p ⬍ .66. When participants’ average latency was included as a
covariate, F(1, 67) ⫽ 3.13, p ⬍ .09, these results did not change:
Control participants showed steeper slopes than did experimental
participants, F(1, 67) ⫽ 5.90, p ⬍ .02, and participants told to
avoid race did not differ from those told to use race, F(1, 67) ⫽
0.51, p ⬍ .70. This analysis suggests that the condition differences
in 1/f noise are not a simple by-product of slower or faster
responses in general.
Analysis of bias in the errors revealed no effects of condition,
Fs(68) ⬍ 1.44, ps ⬎ .23. (Signal detection and process dissociation procedure analyses yield similar results.) Although these data
replicate those of Payne et al. (2002) on a mean level, the relatively

Figure 4. Power spectral density (PSD) slopes for participants in the
absence of any instructions (control), for participants instructed to avoid
the use of racial cues, and for participants instructed to use racial cues,
Study 2.

long time window in the current study may have reduced the
reliability of estimates based on error rates and attenuated the
likelihood of detecting condition differences (see Table 2).
Analysis of bias in reaction times yielded a marginal effect, such
that participants instructed to either avoid or use racial cues during
the weapon-identification task showed greater bias than did participants in the control condition, F(1, 68) ⫽ 2.96, p ⬍ .09. This
effect is consistent with that found by Payne et al. (2002), who
showed that either type of instruction induced greater bias. Participants instructed to use race did not differ from those instructed to
avoid using race, F(1, 68) ⫽ 0.16, p ⬍ .70.
As in Study 1, these results show that participants who attempt
to modulate their behavior on a measure of implicit racial attitudes
show reductions in 1/f noise relative to participants who approach
the task in a more naive fashion. It is important to note that, unlike
Study 1, the current study used an experimental manipulation of
effort by providing participants with randomly assigned instructions. Accordingly, Study 2 provides evidence that effort causally
affects the emission of 1/f noise.

General Discussion
In two studies, I examined residual latencies from computerbased measures of racial bias. The residuals revealed clear evi-

Table 2
Means and Standard Deviations by Condition, Study 2
Condition
Control (n ⫽ 24)
Measure
Slope in PSD
Bias in errors
Bias in latencies (ms)

M

SD

⫺0.45
0.63
⫺4.98

Note. PSD ⫽ power spectral density.
p ⬍ .10. * p ⬍ .05. ** p ⬍ .01.

†

Use race (n ⫽ 25)

**

0.32
2.86
38.43

M
⫺0.29
1.67*
11.69†

**

Avoid race (n ⫽ 22)
SD

M

SD

0.36
3.25
28.14

⫺0.25
0.80*
7.38

**

0.28
1.71
30.54

This document is copyrighted by the American Psychological Association or one of its allied publishers.
This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.

1/f NOISE AND EFFORT ON IMPLICIT MEASURES

dence of nonrandom variability. Consistent with work in cognitive
psychology, error variance was characterized by 1/f noise—a complex pattern of serial dependency that can be assessed through
spectral analysis (Gilden, 2001). Research has shown that this
phenomenon is more pronounced when tasks are easy (rather than
difficult), and in the absence (rather than in the presence) of
memory load (Clayton & Frey, 1997). Whereas in previous work,
the nature of the materials has been manipulated through the use of
fundamentally different computer tasks, in the current research, the
task was held constant across all participants in each study. These
studies investigated variability only in participants’ effort or orientation to a given task. Specifically, in these studies, I examined
the impact of dispositional and experimentally induced efforts to
avoid biased behavior. The hypothesis, building on the work of
Clayton and Frey, suggested that effort would decrease 1/f noise in
tasks related to racial bias.
In Study 1, participants performed a shoot/don’t-shoot task with
Black and White targets. On average, the data showed clear
evidence of 1/f noise (a negative PSD slope). Moreover, the
magnitude of the effect was attenuated (yielding PSD slopes closer
to zero) for participants who reported greater effort. By contrast,
the 1/f pattern was more pronounced among participants who
reported that they did not try to avoid bias during the task. Study
2 experimentally manipulated participants’ effort to control their
behavior in a weapon-identification task (a measure of racial bias;
Payne, 2001). Those who were given additional task demands—
explicit instructions to either use or avoid the use of racial cues—
showed reduced 1/f noise compared with participants in the control
condition who were given no additional demands. Together, these
studies suggest that 1/f noise characterizes response times in
social– cognitive measures of stereotyping and prejudice and (importantly) that these patterns are sensitive to a participant’s taskrelevant effort.
These data have implications for the continuing debate about the
meaning and utility of implicit measures. Like other measures
before them, measures of implicit or automatic attitudes have
gained prominence in social psychology by virtue of their purported ability to assess participants’ views in ways that are relatively insensitive to concerns over social desirability. Clearly,
computer-based implicit measures can be differentiated from simple questionnaire measures, and they seem to offer unique predictive power (Dovidio, Kawakami, & Gaertner, 2002; McConnell &
Leibold, 2001). But there is still a lack of clarity regarding what,
exactly, they measure and how susceptible they truly are to demand (e.g., Karpinski & Hilton, 2001). A number of studies
(Fiedler & Bluemke, 2005; Glaser & Knowles, in press; Hausmann
& Ryan, 2004) have recently shown that a participant’s motivation
to behave in an unbiased fashion (or at least to present him- or
herself as unbiased) can impact measures like the IAT. The current
studies are similarly predicated on the idea that individuals approach even implicit measures with an awareness of the purpose of
the research and with an intention to bring their performance into
line with their goals and standards (Monteith, 1993). Of course,
intention does not, in and of itself, mean that participants will be
successful in their efforts. Indeed, their efforts may even backfire
(Study 2; Payne et al., 2002). But it does imply that individual and
situational differences may affect participants’ orientation to implicit measures in fundamental ways with consequences that can
be hard to predict.

57

Limitations and Future Directions
The current studies constitute the first known application of 1/f
analysis to social psychological research in general and to the
domain of stereotyping and prejudice in particular. This work has
accordingly focused on a single question: Does effort affect 1/f
noise on measures of racial bias? In the current studies, I examined
this question using two operationalizations of effort and two measures of bias. Although some researchers may find these effects
intriguing, it is important to note a few key limitations.

Sensitivity Versus Specificity
First, the current research deals exclusively with the issue of
sensitivity. Each of the studies reported here shows that 1/f noise
depends on or is sensitive to task-relevant effort. At present, there
is no evidence concerning the specificity of the relationship between effort and 1/f noise. Treating 1/f noise as a proxy for effort
is therefore logically problematic (Cacioppo & Tassinary, 1990).
To the extent that other variables increase or decrease the magnitude of the PSD slope, variation in 1/f noise may emerge independent of effort. Future research on other causal factors will likely
improve understanding of 1/f noise and ultimately increase the
utility of this approach.

Mechanism
A second issue, related to the first, is that research has not yet
specified the psychological processes through which effort affects
1/f noise. Previous work has suggested that task difficulty affects
1/f noise (Clayton & Frey, 1997; Ward & Richard, 2001, as cited
in Ward, 2002), and the fact that effort reduces 1/f noise in these
studies certainly seems consistent with the putative role of effort
and/or the possibility that effort imposes additional demands. But
effort is likely to induce a number of more specific psychological
states, which may also give rise to 1/f noise. For example, effort
may produce anxiety if participants worry about revealing some
undesirable bias. It may also increase attention to the task at hand
or even create a dual-task situation such that participants attempt to
simultaneously (a) perform the basic task (e.g., accurately differentiate guns from tools) and (b) modulate the influence of race on
their responses. The mediating role (or roles) of anxiety, attention,
and difficulty must be tested.

Baby or Bathwater?
The measures of 1/f noise used in the current studies are derived
from nothing more than latency data—the kind of data that are
routinely collected in thousands of studies in hundreds of laboratories
every year. These data not only yield estimates of the principal
construct under investigation (e.g., racial bias in the decision to shoot),
they also seem to offer hints about the participants’ orientation to the
task. This information, embedded in the residuals of the latencies, is
typically ignored. To the extent that a researcher’s question does not
concern the participants’ effort, researchers may lose little by disregarding patterns of trial-to-trial variability. In some cases, however,
research may profit tremendously by virtue of this inconspicuous and
generally untapped measure. That is, researchers may be able to
harvest additional information from nothing more than the data they
have already collected.

This document is copyrighted by the American Psychological Association or one of its allied publishers.
This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.

58

CORRELL

As understanding of this phenomenon improves (e.g., as researchers learn about the specificity of 1/f noise), spectral analysis may
provide a tool for the researcher who hopes to mine data sets (new and
old) to examine questions of orientation and effort. Reciprocally,
existing data sets may improve understanding of 1/f noise by allowing
for the identification of variables that moderate and mediate the types
of effects reported here. These possibilities are particularly interesting
in light of recent attempts to measure implicit efforts to control
prejudice (Glaser & Knowles, in press). There has been some speculation that measures of effort to control prejudice may, themselves,
be subject to social desirability concerns. In an individualistic society
like the United States, for example, there may be pressure to endorse
statements such as “I always express my thoughts and feelings,
regardless of how controversial they might be” (Dunton & Fazio,
1997). With additional testing, spectral analysis may allow researchers to assess efforts to avoid prejudice in an almost completely covert
and demand-free fashion.
It may be useful to speculate, briefly, about the IAT, which
has been adopted as the implicit measure of choice in many
laboratories. There is some reason to think that 1/f noise will be
difficult or impossible to evaluate in the context of this popular
measure. The IAT consists of two separate judgment tasks (e.g.,
classifying a face as Black or White, classifying a word as good
or bad), which are mapped onto a single pair of response
options. On one block of trials, a participant might be asked to
press Button 1 if a face is Black or if a word is bad but to press
Button 2 if a face is White or a word is good. If the participant
holds a negative view of Blacks (or a positive view of Whites),
these pairings are congruent. On another block, the participant
would be asked to reorient one of the judgments, now pressing
Button 1 if a face is White or if a word is bad but pressing
Button 2 if a face is Black or a word is good. If this orientation
is inconsistent with his or her views, the participant should
experience greater difficulty. From the perspective of a spectral
analysis, the IAT may prove problematic because the two
blocks of trials involve vastly different degrees of effort, which
should yield different patterns of 1/f noise. In fact, a highly
prejudiced participant is expected to respond quickly, accurately, and easily on the congruent block (which may yield
steep PSD slopes) but slowly, inaccurately, and with great
difficulty on the incongruent block (which may yield flatter
slopes). Analyzing the differences in slope between the blocks
may address this problem, but the FFT procedure requires many
trials to estimate low-frequency waves. Unless the IATs include
sufficient trials in each block, low-frequency data (which are
diagnostic of 1/f noise) may not be available.
For social psychology, 1/f noise and other dynamic approaches
(e.g., Markov analyses) seem to hold tremendous promise. 1/f
noise itself is based on the idea that events at time t may have
implications for time t ⫹ 1 (or t ⫹ 100). That is, 1/f noise can
reflect a dynamic system, where events are not isolated or disconnected but intertwined. Social psychological phenomena that unfold over time (e.g., conversations between individuals, behavioral
mimicry, attraction, intergroup competition) reflect similarly complex influences. Given concern with these processes, analytical
techniques that can address dynamic relationships seem like a
natural fit for the discipline (Vallacher, Read, & Nowak, 2002).

Conclusions
1/f noise is striking because it violates expectations. A visual
inspection of residual latencies in a sequential priming task yields
little in the way of an obvious pattern. The data look random. It is
only through spectral analysis that the underlying pattern becomes
clear. In the current studies, I explore the utility of 1/f noise in the
study of racial bias, but the prevalence of computer-based measures in the discipline of psychology raises the possibility that
social psychologists can readily use spectral analyses to explore
data on a wide variety of topics (e.g., self-esteem, attitudes, negotiation), gaining a deeper understanding of the processes they
study. By so doing, social psychologists may reciprocally provide
a unique perspective on the meaning of 1/f noise.

References
Bak, P. (1990). Self-organized criticality. Physica A, 163, 403– 409.
Cacioppo, J. T., & Tassinary, L. G. (1990). Inferring psychological significance from physiological signals. American Psychologist, 45, 16 –28.
Clayton, K., & Frey, B. (1997). Studies of mental “noise.” Nonlinear
Dynamics, Psychology, and Life Sciences, 1, 173–180.
Correll, J., Park, B., Judd, C. M., & Wittenbrink, B. (2002). The police
officer’s dilemma: Using ethnicity to disambiguate potentially threatening individuals. Journal of Personality and Social Psychology, 83,
1314 –1329.
Devine, P. G., & Elliot, A. J. (1995). Are racial stereotypes really fading?
The Princeton trilogy revisited. Personality and Social Psychology Bulletin, 21, 1139 –1150.
Devine, P. G., Plant, E. A., Amodio, D. M., Harmon-Jones, E., & Vance,
S. L. (2002). The regulation of explicit and implicit race bias: The role
of motivations to respond without prejudice. Journal of Personality and
Social Psychology, 82, 835– 848.
Dovidio, J. F., Kawakami, K., & Gaertner, S. L. (2002). Implicit and
explicit prejudice and interracial interaction. Journal of Personality and
Social Psychology, 82, 62– 68.
Dunton, B. C., & Fazio, R. H. (1997). An individual difference measure of
effort to control prejudiced reactions. Personality and Social Psychology
Bulletin, 23, 316 –326.
Fazio, R. H., Jackson, J. R., Dunton, B. C., & Williams, C. J. (1995).
Variability in automatic activation as an unobtrusive measure of racial
attitudes: A bona fide pipeline? Journal of Personality and Social
Psychology, 69, 1013–1027.
Fiedler, K., & Bluemke, M. (2005). Faking the IAT: Aided and unaided
response control on the implicit association tests. Basic and Applied
Social Psychology, 27, 307–316.
Gilden, D. L. (2001). Cognitive emissions of 1/f noise. Psychological
Review, 108, 33–56.
Gilden, D. L., Thornton, T., & Mallon, M. W. (1995, March 24). 1/f noise
in human cognition. Science, 267, 1837–1839.
Glaser, J., & Knowles, E. D. (in press). Implicit motivation to control
prejudice. Journal of Experimental Social Psychology.
Greenwald, A. G., McGhee, D. E., & Schwartz, J. L. K. (1998). Measuring
individual differences in implicit cognition: The implicit association test.
Journal of Personality and Social Psychology, 74, 1464 –1480.
Hausmann, L. R. M., & Ryan, C. S. (2004). Effects of external and internal
effort to control prejudice on implicit prejudice: The mediating role of
efforts to control prejudiced responses. Basic and Applied Social Psychology, 26, 215–225.
Heibeck, T. H., & Markman, E. M. (1987). Word learning in children: An
examination of fast mapping. Child Development, 58, 1021–1034.
Karpinski, A., & Hilton. J. L. (2001). Attitudes and the Implicit Association Test. Journal of Personality and Social Psychology, 81, 774 –788.

This document is copyrighted by the American Psychological Association or one of its allied publishers.
This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.

1/f NOISE AND EFFORT ON IMPLICIT MEASURES
McConahay, J. B., Hardee, B. B., & Batts, V. (1981). Has racism declined
in America? It depends on who is asking and what is asked. Journal of
Conflict Resolution, 25, 563–579.
McConnell, A. R., & Leibold, J. M. (2001). Relations among the Implicit
Association Test, discriminatory behavior, and explicit measures of
racial attitudes. Journal of Experimental Social Psychology, 37, 435–
442.
Monteith, M. J. (1993). Self-regulation of prejudiced responses: Implications for progress in prejudice reduction efforts. Journal of Personality
and Social Psychology, 65, 469 – 485.
Nosek, B. A., & Banaji, M. R. (2001). The Go/No-Go Association Task.
Social Cognition, 19, 625– 666.
Payne, B. K. (2001). Prejudice and perception: The role of automatic and
controlled processes in misperceiving a weapon. Journal of Personality
and Social Psychology, 81, 181–192.
Payne, B. K., Lambert, A. J., & Jacoby, L. L. (2002). Best laid plans:
Effects of goals on accessibility bias and cognitive control in race-based
misperceptions of weapons. Journal of Experimental Social Psychology,
38, 384 –396.
Plant, E. A., & Devine, P. G. (1998). Internal and external motivation to
respond without prejudice. Journal of Personality and Social Psychology, 75, 811– 832.
Ratcliff, R., Van Zandt, T., & McKoon, G. (1999). Connectionist and
diffusion models of reaction time. Psychological Review, 106, 261–300.
Richeson, J. A., & Trawalter, S. (2005). Why do interracial interactions
impair executive function? A resource depletion account. Journal of
Personality and Social Psychology, 88, 934 –947.

59

Stroop, J. R. (1935). Studies of interference in serial verbal reactions.
Journal of Experimental Psychology, 18, 643– 662.
Thornton, T. L., & Gilden, D. L. (2005). Provenance of correlations in
psychological data. Psychonomic Bulletin & Review, 12, 409 – 441.
Vallacher, R. R., Read, S. J., & Nowak, A. (2002). The dynamical perspective in personality and social psychology. Personality and Social
Psychology Review, 6, 264 –273.
Van Orden, G. C., & Holden, J. G. (2002). Intentional contents and
self-control. Ecological Psychology, 14, 87–109.
Van Orden, G. C., Holden, J. G., & Turvey, M. T. (2003). Selforganization of cognitive performance. Journal of Experimental Psychology: General, 132, 331–350.
Wagenmakers, E.-J., Farrell, S., & Ratcliff, R. (2004). Estimation and
interpretation of 1/f␣ noise in human cognition. Psychonomic Bulletin &
Review, 11, 579 – 615.
Wagenmakers, E.-J., Farrell, S., & Ratcliff, R. (2005). Human cognition
and a pile of sand: A discussion on serial correlations and self-organized
criticality. Journal of Experimental Psychology: General, 134, 108 –116.
Ward, L. M. (2002). Dynamical cognitive science. Cambridge, MA: MIT
Press.
Waxman, S. R., & Klibanoff, R. S. (2000). The role of comparison in the
extension of novel adjectives. Developmental Psychology, 36, 571–581.
Wittenbrink, B., Judd, C. M., & Park, B. (1997). Implicit racial stereotypes
and prejudice and their relationships with questionnaire measures: We
know what we think. Journal of Personality and Social Psychology, 72,
262–274.

Appendix
Example SAS Code
**

This section regresses latencies on independent variables ;
data working;
set datafile;
lntime ⫽ log(latency);
accurate ⫽ 1*(response ⫽ ‘correct’)
⫺1*(response ⫽ ‘incorrect’);
proc reg noprint;
model lntime ⫽ racecode objectcode
racexobjcode trialnumber accurate;
output out⫽outputfile1 r⫽residual;
by participantnumber;
run;
data outputfile1;
set outputfile1;
**

This section performs a fast Fourier transform for each participant ;
proc spectra adjmean p s out⫽outputfile2;
var residual;
weights tukey;
by participantnumber;
run;

**
This step removes a constant or DC component from the PSD
estimates ;
data outputfile2;
set outputfile2;
if freq ne 0;
**

This step log transforms power and frequency estimates ;
lnpower ⫽ log(p_01);
lnfreq ⫽ log(freq);

**

This section removes high-frequency data (LN⬎ZERO) and
computes linear relation between power & frequency for each participant, saving coefficients to a final data file called outputfile3 ;
data outputfile2;
set outputfile2;
if lnfreq ⬍ 0;
proc reg noprint outest ⫽ outputfile3;
model lnpower ⫽ lnfreq;
by participantnumber;
run;
Received April 28, 2006
Revision received June 23, 2007
Accepted July 12, 2007 䡲

