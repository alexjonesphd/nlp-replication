Journal of Experimental Psychology:
Learning, Memory, and Cognition
2008, Vol. 34, No. 2, 353–368

Copyright 2008 by the American Psychological Association
0278-7393/08/$12.00 DOI: 10.1037/0278-7393.34.2.353

Tracing Attention and the Activation Flow in Spoken Word Planning
Using Eye Movements
Ardi Roelofs

This document is copyrighted by the American Psychological Association or one of its allied publishers.
This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.

Radboud University Nijmegen
The flow of activation from concepts to phonological forms within the word production system was
examined in 3 experiments. In Experiment 1, participants named pictures while ignoring superimposed
distractor pictures that were semantically related, phonologically related, or unrelated. Eye movements
and naming latencies were recorded. The distractor pictures affected the latencies of gaze shifting and
vocal naming. The magnitude of the phonological effects increased linearly with latency, excluding
lapses of attention as the cause of the effects. In Experiment 2, no distractor effects were obtained when
both pictures were named. When pictures with superimposed distractor words were named or the words
were read in Experiment 3, the words influenced the latencies of gaze shifting and picture naming, but
the pictures yielded no such latency effects in word reading. The picture–word asymmetry was obtained
even with equivalent reading and naming latencies. The picture–picture effects suggest that activation
spreads continuously from concepts to phonological forms, whereas the picture–word asymmetry
indicates that the amount of activation is limited and task dependent.
Keywords: attention, cascade processing, eye movements, word production

to level in an automatic and continuous fashion or whether the
activation flow is discrete and goal dependent at some points in the
network (for recent discussions see, e.g., Bloem & La Heij, 2003;
Morsella & Miozzo, 2002; Navarrete & Costa, 2005; Roelofs,
2003).
Up until now, the discussions in the literature on spoken word
planning have typically concentrated on the two most extreme
theoretical positions (but see Dell & O’Seaghdha, 1991): The
spread of activation is either automatic and continuous versus
discrete and goal dependent at some points. However, according to
a third intermediate theoretical position, which is explored in the
present article, activation spreads from level to level in a continuous fashion, but the amount of activation that spreads through the
system is limited and task dependent. For example, following Dell
(1986), I proposed in several articles (e.g., Roelofs, 1992, 1997,
2003) that retrieval of information from the lexical network involves selective attentional enhancement of the activation of goalrelated nodes (cf. LaBerge, 1995; Posner & Dehaene, 1994). The
enhancements occur only when the task requires the retrieval of
lexical information. Activation of nodes decreases with network
distance. In the absence of activation enhancements, the network
distance between concepts and phonological forms is too long to
obtain much phonological activation induced by concepts. In addition, the connections between lemmas and word forms may be
weak, which limits the amount of activation that spreads between
levels at this point in the lexical network (Roelofs, 2003).
Levelt et al. (1999) argued that perceived objects continuously
activate their concepts and lemmas, whereas the morphemes, phonemes, and motor programs of the object names are activated only
when a speaker has the goal of naming the objects and selects a
lemma. Lemma selection is goal dependent, and the goal of object
naming allows the connection between lemmas and word forms to
be made. Consequently, only the form corresponding to a selected
lemma becomes activated. For example, in referring to a perceived

Does activation spread in an automatic and continuous fashion
through associative memory, or is the activation flow discrete and
goal dependent at some points? This issue has been intensively
investigated in the cognitive and brain sciences (e.g., D. E. Meyer,
Osman, Irwin, & Yantis, 1988). Following a seminal study by
Levelt et al. (1991), the nature of the flow of activation has also
been a major issue in psycholinguistic research on object naming.
The naming of objects seems to involve the activation of concepts,
lemmas, morphemes, phonemes, and syllable motor programs in
associative memory (e.g., Levelt, Roelofs, & Meyer, 1999). Lemmas code the words’ syntactic properties. For example, in the
WEAVER⫹⫹ model (Levelt et al., 1999; Roelofs, 1992, 1997,
2003), the conceptually driven production of the word cat involves
the activation in a lexical network of the representation of the
concept CAT(X), the lemma of cat specifying that the word is a
noun (for languages such as Dutch, lemmas also specify grammatical gender), the morpheme ⬍cat⬎, the phonemes /k/, /æ/, and /t/,
and the syllable motor program [kæt]. A fragment of the lexical
network of WEAVER⫹⫹ is illustrated in Figure 1. No consensus
exists in the literature as to whether activation spreads from level

Ardi Roelofs, Nijmegen Institute for Cognition and Information and
F. C. Donders Centre for Cognitive Neuroimaging, Radboud University
Nijmegen, the Netherlands.
I am indebted to Bicoor Bolla-Bong for his help in preparing and
running the experiments and to Kim Verhoef, Markus Damian, and the
members of the Utterance Encoding Group of the Max Planck Institute for
Psycholinguistics in Nijmegen for helpful comments. The preparation of
this article was supported by a Vici grant from the Netherlands Organization for Scientific Research.
Correspondence concerning this article should be addressed to Ardi
Roelofs, Nijmegen Institute for Cognition and Information, Radboud University Nijmegen, Spinoza Building B.01.08, Montessorilaan 3, 6525 HR
Nijmegen, the Netherlands. E-mail: A.Roelofs@nici.ru.nl
353

ROELOFS

354

perceived
object
FELINE(X)

CAT(X)

noun

perceived
word
This document is copyrighted by the American Psychological Association or one of its allied publishers.
This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.

concepts

DOG(X)

cat

dog

<cat>

<dog>

lemmas

CAT

/k/

/æ/

/t/

[kæt]

/d/

/ /
[d g]

morphemes

/g/

phonemes

syllable motor
programs

Figure 1. Fragment of the lexical network of the WEAVER⫹⫹ model of spoken word production (Levelt et
al., 1999; Roelofs, 1992, 2003).

cat by saying “cat,” the concepts CAT(X) and DOG(X), the
lemmas of cat and dog, and the phonological form of cat become
activated, but the form of dog remains inactive. In contrast, other
researchers (e.g., Dell, 1986) have argued that all word forms
corresponding to the activated concepts and lemmas become continuously activated. According to this view, the form of dog is also
activated in planning to say “cat.” More recently, Altmann and
Davidson (2001) and Bloem and La Heij (2003) argued that
although objects activate their concepts and related ones, the
lemmas, morphemes, phonemes, and motor programs of the object
names are activated only when a speaker has the goal of naming
the objects. In seeing a cat, the concepts CAT(X) and DOG(X)
become activated, but the lemma and form of cat become active
only when a speaker wants to name the cat. Thus, whereas Dell
(1986) and Levelt et al. (1999) assumed that activation spreads
continuously from concepts to lemmas, Altmann and Davidson
and Bloem and La Heij argued that the activation flow is discrete
in that only a selected concept activates its lemma. Moreover,
whereas Dell assumed that activation spreads continuously from
lemmas to word forms, Levelt et al. (1999) argued that the spread
of activation is discrete in that only a selected lemma activates its
word form.

Review of Empirical Evidence
Seminal evidence that activation spreads continuously from
concepts to lemmas but not from lemmas to word forms came from
a series of experiments by Levelt et al. (1991). They tested for the
activation of the phonological form of semantic competitors of a
picture name. For example, is the phonological form of the word
dog activated in naming a pictured cat? Participants were asked to
name pictured objects (e.g., a pictured cat) and, on some critical

trials, to interrupt the preparation of the picture name and decide
whether an auditory probe presented after picture onset was a word
or not (auditory lexical decision). If activation spreads continuously from concepts to phonological forms, the phonemes of
semantic competitors of the target (e.g., the phoneme /d/ of the
word dog, which is a semantic competitor of cat) should become
active. Levelt et al. (1991) obtained no effect on the lexical
decision latencies for spoken probes that were phonologically
related to semantic competitors (e.g., the probe DOLL, which is
phonologically related to dog), whereas they obtained interference
for probes that were semantic competitors (DOG) or directly
phonologically related (CAP). These results support the view that
activation spreads continuously from concepts to lemmas, yielding
the semantic interference for semantic competitors (DOG), but not
from lemmas to word forms, explaining the lack of activation for
the phonemes of those semantic competitors (e.g., the /d/ of DOG),
as indexed by the absence of an effect on DOLL (see also Jescheniak, Hahne, & Schriefers, 2003).
Using word reading rather than auditory lexical decision, Peterson and Savoy (1998) replicated the findings of Levelt et al.
(1991). However, whereas Levelt et al. (1991) obtained semantic
and phonological interference effects on the lexical decisions,
Peterson and Savoy obtained semantic and phonological facilitation of word reading. Clearly, the direction of the effects (interference versus facilitation) depends on the task. Moreover, Peterson and Savoy reported activation of the phonological form of
near-synonyms of the picture name (e.g., for PULL, related to
puss, in naming a pictured cat), indicating that the phonological
activation of semantic competitors may be detected when the
semantic relation between words is strong. This suggests that
activation in the word production system cascades between levels.

This document is copyrighted by the American Psychological Association or one of its allied publishers.
This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.

ACTIVATION FLOW IN SPOKEN WORD PLANNING

Alternatively, it may be that near-synonyms are a special case.
Levelt et al. (1999) suggested that speakers habitually or mistakenly select both words in cases of near-synonymy and repair the
multiple selection later in the planning process (e.g., after phonological encoding). According to this view, the activation of the
forms of near-synonyms is the result of misselection and covert
repair rather than a continuous spread of activation from lemmas to
forms.
Griffin and Bock (1998) argued, however, specifically for the
continuous activation view. They observed that the effect of word
frequency (i.e., high-frequency words are produced faster than
low-frequency words) is smaller in syntactically constrained than
unconstrained sentential contexts. Earlier evidence suggested that
the effect of word frequency arises during accessing lexical forms
or morphemes (Jescheniak & Levelt, 1994; Roelofs, 1998). If the
transition from lemma to word form is a discrete step, then
syntactic constraint and word frequency should yield additive
effects. Setting aside misselection, the interaction between syntactic constraint and word frequency therefore suggests that activation
spreads continuously from lemmas to word forms. Furthermore,
Cutting and Ferreira (1999) observed that when speakers named
pictures of objects with a homophone name (e.g., they said “ball”
to a toy ball, whereby the other meaning of ball was party), an
auditory distractor word that was semantically related to the other
meaning (DANCE) speeded picture naming relative to an unrelated control. This suggests that hearing a distractor like DANCE
activated the other meaning of ball (party), which automatically
activated the word form of ball, speeding the naming of the toy
ball. More recently, Morsella and Miozzo (2002) presented the
primes directly as distractor pictures in picture naming. Speakers
were given pictures in green superimposed onto pictures in red.
The task was to name the pictures in green while ignoring the
pictures in red. The picture names were phonologically related or
unrelated. Morsella and Miozzo observed that target pictures were
named faster when the distractor picture was phonologically related than when it was unrelated. This suggests that activation
spreads continuously from the distractor picture to the phonological form of its name. Navarrete and Costa (2005) replicated and
extended these findings. Taken together, the empirical evidence
seems to favor the position of Dell (1986) over the positions of
Levelt et al. (1999), Altmann and Davidson (2001), and Bloem and
La Heij (2003). Activation seems to cascade from concepts to
phonological forms.
Other evidence indicates, however, that the amount of activation
that spreads from concepts to phonological forms is limited, in line
with the data of Levelt et al. (1991) and Peterson and Savoy
(1998). It is often assumed that pictures have direct access to
concepts and only indirect access to word forms, whereas words
have direct access to word forms and only indirect access to
concepts (cf. Roelofs, 1992, 2003), as illustrated in Figure 1.
Naming pictures requires concept selection, whereas words can be
read aloud without concept selection. The latter is achieved by
mapping input word-forms (e.g., CAT) directly onto output wordforms (e.g., ⬍cat⬎, /k/, /æ/, /t/, and [kæt]), as illustrated in
Figure 1. Semantically related written words (e.g., DOG) superimposed onto pictured objects (e.g., a cat) hamper the naming of
the objects. However, the pictures have no effect on reading the
words aloud (e.g., M. O. Glaser & Glaser, 1982; W. R. Glaser &
Düngelhoff, 1984; W. R. Glaser & Glaser, 1989; Roelofs, 2003,

355

2006a, 2006b; Smith & Magee, 1980; see MacLeod, 1991, for a
review). The absence of an effect of picture distractors on word
reading suggests that the amount of activation that spreads from
pictures to word forms is limited (Roelofs, 2003). One may argue
that the interference of pictures on word reading is absent because
words are read without accessing the mental lexicon, namely via
the application of grapheme–phoneme correspondence rules (e.g.,
mapping the c of cat onto /k/), and that the rule application shields
word reading from distracting pictures. However, that does not
seem to be the case. Digits (e.g., the digit 3) superimposed onto
dice (e.g., two dots) affect dice naming, whereas the dice have no
effect at all on digit naming (Roelofs, 2006b). However, digits
cannot be read by applying grapheme–phoneme correspondence
rules. This suggests that the absence of an effect of pictures/dice on
word reading is due to the limited amount of activation spreading
from pictures/dice to word forms (see Roelofs, 2003, 2006a,
2006b, for further discussion).
Bloem and La Heij (2003) argued that the finding of Morsella
and Miozzo (2002) concerning the effect of a phonological relation
between target and distractor pictures is problematic in the light of
the finding by Damian and Bowers (2003) that a semantic relation
between pictures does not yield an effect. Navarrete and Costa
(2005) also obtained no semantic effect of picture distractors on
picture naming latencies. According to Bloem and La Heij, if a
distractor picture has no semantic effect on naming another picture, suggesting that activation does not spread continuously from
concepts to lemmas, it is surprising that a phonological relationship has an effect, suggesting a continuous spread of activation
from concepts to lemmas and from lemmas to word forms. The
reasoning of Bloem and La Heij is not completely convincing,
however.
First, whereas Damian and Bowers (2003) obtained no semantic
effect of picture distractors on picture naming, W. R. Glaser and
Glaser (1989) obtained semantic interference. It seems that the
difference in effects between studies is related to methodological
differences. Whereas in the study of Damian and Bowers the
superimposed pictures differed in size and the participants had to
name the largest picture, in the study of W. R. Glaser and Glaser
the onset of the presentation of the two pictures differed, and
participants had to name the first (or second) picture that appeared
on the screen. Using the same technique as W. R. Glaser and
Glaser, La Heij, Heikoop, Akerboom, and Bloem (2003) replicated
the semantic interference. Moreover, in a second experiment, the
selection of the target picture was made easier by reducing the
presentation duration of the distractor picture. Then semantic facilitation was obtained. On the basis of these findings, La Heij et
al. concluded that “the ease of target selection is at least one of the
factors that contributed to the reversal from semantic interference
in Experiment 1 into semantic facilitation in Experiment 2” (p. 58).
To conclude, in contrast to what Bloem and La Heij (2003)
maintained, picture distractors may yield semantic effects, depending on the task situation.
Second, the model of word planning proposed by Bloem and La
Heij (2003) does not distinguish between lexical selection and
phonological encoding, so semantic and phonological effects are
expected to co-occur. This makes the presence of a phonological
effect in the absence of a semantic effect surprising. However,
other models attribute semantic and phonological effects to different planning processes. For example, the WEAVER⫹⫹ model

ROELOFS

This document is copyrighted by the American Psychological Association or one of its allied publishers.
This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.

356

assumes that lemma retrieval and phonological encoding are distinct processes, which are differentially sensitive to semantic and
phonological manipulations, as is evident, for example, from the
difference in time course of semantic and phonological effects
(Levelt et al., 1999). Thus, phonological manipulations may have
an effect even when semantic manipulations do not (cf. Schriefers,
Meyer, & Levelt, 1990).
These two arguments against the reasoning of Bloem and La
Heij (2003) do not mean, however, that the picture–picture results
obtained by Morsella and Miozzo (2002) and Navarrete and Costa
(2005) provide straightforward evidence for cascading. As the
results of La Heij et al. (2003) indicate, how participants deal with
the selective attention problem posed by naming one of two
superimposed pictures is in itself a complicated issue (e.g., Allport,
Tipper, & Chmiel, 1985). Participants have to name the green
picture and ignore the red picture. A theoretical possibility is that
participants plan the names of both pictures and then finally select
the motor program for the green picture name from an articulatory
buffer and initiate articulation (Roelofs, 2006a). Thus, the phonological facilitation might arise from a particular planning strategy
adopted for dealing with the selective attention problem posed by
overlapping pictures rather than reflect a continuous spread of
activation.

Overview of the Present Experiments
Research on spoken word planning has shown that there is a
close link between phonological activation and gaze shifting in
picture naming (e.g., A. S. Meyer, Sleiderink, & Levelt, 1998;
Griffin, 2001), whereby gaze shifts index shifts of attention (Roelofs, 2007). For example, when speakers are asked to name two
objects in a row, they look longer at first-to-be-named objects with
two- versus one-syllable names even when the object recognition
times are the same (A. S. Meyer, Roelofs, & Levelt, 2003). The
effect of the phonological length suggests that the shift of gaze
from one object to the other is initiated only after the phonological
form of the name for the object has been planned sufficiently (cf.
Korvorst, Roelofs, & Levelt, 2006; Levelt & Meyer, 2000). A. S.
Meyer and Van der Meulen (2000) observed that phonologically
related spoken distractor words reduce picture naming latencies
and gaze shift latencies compared to phonologically unrelated
distractors. Thus, again, gaze shifts were linked to phonological
activation. Moreover, Levelt and Meyer (2000) and Korvorst et al.
(2006) observed that gaze shift latencies may reflect the phonological length of the utterance even when vocal response latencies
do not. If distractor pictures activate the phonological form of their
names, they should affect not only the latency of naming the target
pictures but also the latency of gaze shifting. Earlier research
suggests that the variability in latencies tends to be less for gaze
shifting than for vocal responding (A. S. Meyer et al., 2003; A. S.
Meyer & Van der Meulen, 2000). Effects in the picture–picture
task tend to be small (around 10 –20 ms in the studies of La Heij
et al., 2003; Morsella & Miozzo, 2002; Navarrete & Costa, 2005).
By measuring gaze shift latencies in addition to vocal response
latencies, the chances are enhanced for detecting the effects if they
are there.
The present article reports three eye-tracking experiments that
further explored the issue of the extent to which activation spreads
between word planning levels and how the activation flow is

influenced by attention. In particular, the reported research examined effects of picture distractors in naming one of two superimposed pictures (Experiment 1), naming both pictures (Experiment
2), and reading words (Experiment 3). In all the experiments, the
target was presented in green color and the distractor in red.
Experiment 1 concerned a replication and extension of the studies
of Morsella and Miozzo (2002) and Navarrete and Costa (2005).
Different from Morsella and Miozzo, all pictures occurred both as
targets and distractors. This manipulation served to optimize a
comparison between Experiment 1 and Experiment 2, where both
pictures had to be named, and therefore both were part of the
response set. The picture–picture stimuli (Experiments 1 and 2)
and picture–word stimuli (Experiment 3) were presented on the
left-hand side of a computer screen. To give the participants an
incentive to move their gaze away from the picture–picture or
picture–word stimuli, a secondary stimulus requiring a manual
response was presented on the right-hand side of the screen. This
response involved pressing a left or right button to indicate the
direction of a left- or right-pointing arrow.
Phonological effects in the picture–picture task do not necessarily support a continuous spread of activation within the word
production system. The effects may also be obtained when speakers mistakenly select the names of both pictures, as suggested by
Levelt et al. (1999) for synonyms. Bloem, Van den Boogaard, and
La Heij (2004) suggested that lapses of attention, leading to an
erroneous selection of the wrong picture name on some of the
trials, explain the picture–picture effects observed by Morsella and
Miozzo (2002). The robustness of the effects was tested by examining the latency distributions in Experiment 1. If phonological
effects are due to an erroneous selection of the red picture name on
some of the trials, followed by a covert repair, the effects should
be present for only a part of the latency distribution, namely for the
slow responses only. Instead, if the effects reflect cascading of
activation, the difference in the latency between the related and
unrelated conditions should be present through most of the latency
range. The latency distributions were examined using “quantile–
quantile” plots (Thomas & Ross, 1980; Wilk & Gnanadesikan,
1968). A quantile– quantile plot is a standard technique for determining whether two distributions belong to the same distribution
family. If they do, the plot should be linear, indicating that the
distributions differ only by a scale or shift factor. Linearity in a
distribution plot indicates that the difference between conditions
varies proportionately with latency (e.g., De Jong, Liang, &
Lauber, 1994; Ridderinkhof, 2002; Zhang & Kornblum, 1997). If
a linear function is obtained, this would exclude that the effects are
caused by lapses of attention.
Selecting the names of both pictures may be the way that
participants deal with the selective attention problem in the
picture–picture task. Experiment 2 explicitly examined the effect
of multiple selection. On each trial, participants named both pictures, first the green one and then the red one. If the phonological
effects in Experiment 1 are due to the selection of the names of
both the green and the red pictures, the results from naming one
picture in Experiment 1 should be replicated with the naming of
both pictures in Experiment 2.
The absence of an effect of picture distractors on word reading
reported in the literature suggests that the amount of activation that
spreads from concepts to word forms is limited and attention
dependent (Roelofs, 2003). Experiment 3 examined the influence

ACTIVATION FLOW IN SPOKEN WORD PLANNING

of picture distractors on word reading using picture–word versions
of the stimuli used in Experiments 1 and 2. Participants named the
picture or word of picture–word stimuli depending on whether the
picture or word was presented in green (the picture or word in red
had to be ignored), which varied randomly from trial to trial. If
phonological effects of picture distractors are obtained on picture
naming (Experiment 1) but not on word reading (Experiment 3),
this would corroborate the existing evidence that the amount of
activation spreading from concepts to word forms is limited and
task dependent.

This document is copyrighted by the American Psychological Association or one of its allied publishers.
This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.

Experiment 1
In the first experiment, participants were presented with green
pictures superimposed onto red pictures. Eye movements were
recorded while participants named the green picture of the picture–
picture stimuli (presented on the left side of a computer screen)
and manually responded by pressing a left or right button in
response to the left- or right-pointing arrows (⬍ or ⬎, presented on
the right side of the screen). For example, they said “hammer” in
response to a pictured hammer in green color, while trying to
ignore a pictured chisel in red (the semantically related condition)
or a pictured sandal in red (the semantically unrelated condition).
Or they said “circle” in response to a pictured circle in green, while
trying to ignore a pictured circus in red (the phonologically related
condition) or a pictured table in red (the phonologically unrelated
condition). To minimize the chance that participants would identify the direction of the arrows by their peripheral vision, the
arrows were flanked by two Xs on each side, yielding XX ⬍XX and
XX⬎ XX as stimuli.

Method
Participants. The experiment was carried out with a group of
24 paid participants from the pool at the Max Planck Institute for
Psycholinguistics in Nijmegen. All participants were young adults
who were native speakers of Dutch. None of the participants took
part in one of the other experiments.
Materials and design. From the picture gallery available at the
Max Planck Institute, 40 pictured objects were selected. All pictures had disyllabic names. The pictures were chosen such that 10
pairs of pictures had names that were semantically related and the
10 remaining pairs had names that were phonologically related.
The pictures with phonologically related names shared the first
syllable. The unrelated conditions were created by recombining the
pictures such that each semantically related picture also served as
a semantically unrelated picture and each phonologically related
picture also served as a phonologically unrelated picture. The
Appendix lists the materials. The pictures were line drawings on a
black background. They were digitized and scaled to fit into a
virtual frame of 10 cm ⫻ 10 cm. On average, the pictures subtended 8.7° horizontally and 8.7° vertically at a viewing distance
of 66 cm (roughly the distance between the participant and the
screen). The arrows were presented in 28-point uppercase Arial
font, subtending 3.5° horizontally and 0.9° vertically. The horizontal distance between the middle of the picture–picture stimuli
and the arrow stimuli was 15.2°.
There were two independent variables: type and relation. The
variable type indicated whether the pictures were from the semantic or

357

the phonological sets. The variable relation indicated whether the
paired pictures were related or unrelated. Both variables were tested
within participants. Relation was tested within items and type was
tested between items. A participant received 20 picture–picture pairings in each of the four distractor conditions, yielding 80 picture–
picture stimuli in total. Each picture pair was presented twice, yielding
160 trials per participant in total. The order of presenting the stimuli
across trials was random, except that repetitions of pictures and words
on successive trials were not permitted.
Apparatus. Materials were presented on a 39-cm ViewSonic
17PS screen. Eye movements were measured using an SMI
EyeLink-HiSpeed 2D headband-mounted eye-tracking system
(SensoMotoric Instruments GmbH, Teltow, Germany). The eye
tracker was controlled by a Pentium 90 MHz computer. The
experiment was run under the Nijmegen Experiment Setup
(NESU) with a NESU button box on a Pentium 400 MHz computer. The participants’ utterances were recorded over a
Sennheiser ME400 microphone to a SONY DTC55 digital audio
tape (DAT) recorder. Vocal response latencies were measured
using an electronic voice key.
Procedure. The participants were tested individually. They
were seated in front of the computer monitor, a panel with a left
and a right push button, and the microphone. The distance between
participant and screen was approximately 66 cm. Participants were
given written instructions telling them how their eyes would be
monitored and what the task was. The experimenter also orally
described the eye-tracking equipment and restated the instructions.
The participants were told that they had to name the green picture
of picture–picture stimuli presented on the left side of a computer
screen and manually respond by pressing a left or right button in
response to the arrows presented on the right side of the screen. To
familiarize them with the pictures, the participants received a
booklet showing them all pictures used in the experiment together
with the expected names.
When a participant had read the instructions and studied the
picture booklet, the headband of the eye-tracking system was
placed on the participant’s head, and the system was calibrated and
validated. For pupil-to-gaze calibration, a grid of 3 ⫻ 3 positions
had been defined. During a calibration trial, a fixation target
appeared once, in random order, in each of these positions for one
second. Participants were asked to fixate upon each target until the
next target appeared. After the calibration trial, the estimated
positions of the participant’s fixations and the distances from the
fixation targets were displayed to the experimenter. Calibration
was considered adequate if there was at least one fixation within
1.5° of each fixation target. When calibration was inadequate, the
procedure was repeated, sometimes after adjusting the eye cameras. Successful calibration was followed by a pupil-to-gaze validation trial. For the participants, this trial did not differ from the
calibration trial, but the data collected during the validation trial
were used to estimate the participants’ gaze positions, and the error
(i.e., the distance between the estimated gaze position and the
target position) was measured. Validation was considered completed if the average error was less than 1.0° and the worst error
less than 1.5°. Depending on the result of the validation trial, the
calibration and validation trials were repeated or testing began.
After successful calibration and validation, a block of 40 practice trials was administered, in which each picture was shown and
named once. This was followed by the 160 experimental trials. The

ROELOFS

This document is copyrighted by the American Psychological Association or one of its allied publishers.
This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.

358

structure of a trial was as follows. A trial started by the simultaneous presentation of the left picture–picture and right arrow
stimuli. The stimuli remained on the screen until the participant
pushed the button in response to the arrow. The arrows were
presented in white. The colored pictures and the arrows were
presented on a black background. Before the start of the next trial
there was a blank interval of 1.5 sec. The position of the left and
right eyes was determined every 4 ms. Drift correction occurred
automatically after every 8 trials.
Analyses. A naming response was considered to be invalid
when it included a speech error, when a wrong word was produced, or when the voice key was triggered incorrectly. Error trials
were discarded from the analyses of the naming latencies and gaze
shift latencies. To analyze the speakers’ gaze shifts, their eye
fixations were classified as falling within or on the outer contours
of the left stimulus or elsewhere. Although viewing was binocular
and the positions of both eyes were tracked, only the position of
the right eye was analyzed. Gaze shift latency was defined as the
time interval between the beginning of the first fixation on the left
stimulus and the end of the last fixation before the first shift of
gaze was initiated to the right arrow. The vocal response latencies,
gaze shift latencies, and errors were submitted to analyses of
variance. The analyses were performed both by participants (F1)
and by items (F2). Faster responding in the related than unrelated
condition will be called descriptively facilitation and slower responding will be called interference.

Results and Discussion
Table 1 gives for each distractor condition the mean latencies,
their standard deviations, and the error percentages for the vocal
responses and gaze shifts. The table shows that the vocal naming
latencies were slightly shorter (11 ms) in the semantically related
than unrelated condition, and the gaze shift latencies showed a
similar, but larger effect (25 ms). The latencies were shorter in the
phonologically related than unrelated condition for both the vocal
responses and the gaze shifts (respectively, 29 and 27 ms).
Vocal responses. The statistical analysis of the vocal response
latencies yielded a main effect of relation (related vs. unrelated),
F1(1, 23) ⫽ 12.14, MSE ⫽ 799, p ⫽ .002; F2(1, 38) ⫽ 5.59,
MSE ⫽ 1,436, p ⫽ .02, but not of type (semantic vs. phonological), F1(1, 23) ⫽ 6.86, MSE ⫽ 1,069, p ⫽ .02; F2(1, 38) ⬍ 1,
MSE ⫽ 7,571, p ⫽ .40. Type and relation did not interact, F1(1,
23) ⫽ 1.60, MSE ⫽ 1,401, p ⫽ .22; F2(1, 38) ⫽ 1.43, MSE ⫽
1,436, p ⫽ .24. There was a by-items effect of type on the error

Table 1
Mean Latencies (ms), Standard Deviations (SD), and Error
Percentages (E%) per Type and Relation for the Vocal
Responses and Gaze Shifts in Experiment 1
Vocal

Gaze

Type

Relation

M

SD

E%

M

SD

Semantic

Related
Unrelated
Related
Unrelated

805
816
779
808

213
238
198
207

2.1
2.1
0.7
1.7

653
678
634
661

179
185
174
176

Phonological

rates, F1(1, 23) ⫽ 2.77, p ⫽ .11; F2(1, 38) ⫽ 4.98, p ⫽ .03. There
were no other effects on the errors (all ps ⬎ .10).
Although type and relation did not interact, the magnitude of the
relatedness effect was numerically smaller for the semantic than
for the phonological distractors. Planned comparisons between the
related and unrelated conditions within the semantic and phonological conditions separately revealed that the semantic effect did
not reach significance, t1(23) ⫽ 1.0, p ⫽ .33; t2(19) ⫽ 1.17, p ⫽
.26, but there was a phonological effect, t1(23) ⫽ 3.45, p ⫽ .002;
t2(19) ⫽ 2.05, p ⫽ .05. This suggests that the relatedness effect
was driven by the phonological distractors.
Gaze shifts. The statistical analysis of the gaze shift latencies
yielded a main effect of relation, F1(1, 23) ⫽ 23.14, MSE ⫽ 709,
p ⫽ .001; F2(1, 38) ⫽ 5.72, MSE ⫽ 2,512, p ⫽ .02, but not of type,
F1(1, 23) ⫽ 6.58, MSE ⫽ 1,206, p ⫽ .02; F2(1, 38) ⬍ 1, MSE ⫽
7,374, p ⫽ .40. Type and relation did not interact, F1(1, 23) ⬍ 1,
MSE ⫽ 774, p ⫽ .88; F2(1, 38) ⬍ 1, MSE ⫽ 2,512, p ⫽ .80.
Planned comparisons between the related and unrelated conditions
within the semantic and phonological conditions separately
showed that there were semantic and phonological effects in the
analysis by participants, respectively, t1(23) ⫽ 3.47, p ⫽ .002;
t2(19) ⫽ 1.91, p ⫽ .07, and t1(23) ⫽ 3.21, p ⫽ .004; t2(19) ⫽ 1.60,
p ⫽ .13. Whereas the main effect of relation was significant both
by participants and by items, the relatedness effects within the
semantic and phonological conditions separately reached significance in the analysis by participants only, presumably because
dividing the pictures by type reduced the power of the analysis by
items. To conclude, the effects obtained for the vocal response
latencies were basically replicated for the gaze shift latencies,
except that the semantic effect was now more robust.
To summarize, the experiment replicated the facilitation effect
of phonological relatedness obtained by Morsella and Miozzo
(2002) and Navarrete and Costa (2005) not only for the vocal
responses but also for the corresponding gaze shifts. The effect of
phonological relatedness of two pictures was obtained in the
context of a semantic facilitation effect, which was present in the
gaze shift latencies. Table 1 suggests that the difference in semantic effect between vocal responding and gaze shifting may be due
to greater variability in the vocal latency data. The standard deviations of the latencies tended to be greater for the vocal responses
than for the gaze shifts and greater for the semantic than for the
phonological conditions. This may explain why there was no
robust semantic effect in the vocal responses.
Bloem et al. (2004) suggested that erroneously selecting the
wrong picture name on some of the trials explains the phonological
picture–picture effects, as observed by Morsella and Miozzo
(2002) and in the present experiment. This hypothesis was evaluated by examining the latency distributions for the vocal responses
and gaze shifts in the phonologically related and unrelated conditions. To obtain the latency distributions, I divided the rankordered latencies for each participant into deciles (10% quantiles)
and computed mean latencies for each decile, separately for the
vocal responses and gaze shifts and for the phonologically related
and unrelated conditions. By averaging these means across participants, so-called Vincentized cumulative distribution functions are
obtained (Ratcliff, 1979). Vincentizing the latency data across
individual participants provides a way of averaging data while
preserving the shapes of the individual distributions. Figure 2
shows the distributional plots for Experiment 1. Rank-ordering the

ACTIVATION FLOW IN SPOKEN WORD PLANNING

359

RELATION

CUMULATIVE RELATIVE FREQUENCY

unrelated

1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
400

600

800

1000

1200

GAZE SHIFT LATENCY (ms)

600

800

1000

1200

VOCAL RESPONSE LATENCY (ms)

Figure 2. Vincentized cumulative distribution curves for the vocal responses and gaze shifts in the phonologically related and unrelated conditions of Experiment 1.

R 2 = 0.9939

1100

900

700

500

300
300

500

700

900

1100

RELATED GAZE-SHIFT LATENCY (ms)

analyses revealed that the increase of the phonological effect with
latency was not disproportionate. The latencies in the related and
unrelated conditions were linearly related for both the vocal responses and the gaze shifts, as illustrated by the quantile– quantile
plots in Figure 3. The figure shows the relationship between
condition distributions based on a grouping of the latencies by
participants. Grouping of the latencies by items (not shown)
yielded the same results. This finding of a linear relationship
between latencies excludes an interpretation of the phonological
effects in terms of lapses of attention (Bloem et al., 2004).

Experiment 2
In the second experiment, participants were presented with the
same picture–picture stimuli as in Experiment 1. Eye movements
UNRELATED VOCAL-RESPONSE LATENCY (ms)

latencies for each item and using these to compute Vincentized
cumulative distribution functions yielded equivalent distributional
plots (which are not shown).
Figure 2 shows that the phonological effect was present
throughout the entire latency range for the gaze shifting, except in
the 10% quickest gaze shifts. This suggests that when gaze shifts
occur really early, before phonological encoding, no phonological
effect is obtained. The phonological effect was present across the
entire latency distribution for the vocal responses. For both the
vocal responses and gaze shifts, the difference between the related
and unrelated conditions increased with latency. Statistical analysis revealed that there was no interaction of relation (related vs.
unrelated) and decile (1–10) for the vocal responses, F(9, 207) ⫽
1.18, MSE ⫽ 3,266, p ⫽ .31, but there was an interaction for the
gaze shifts, F(9, 207) ⫽ 3.73, MSE ⫽ 3,055, p ⫽ .001. Further

UNRELATED GAZE-SHIFT LATENCY (ms)

This document is copyrighted by the American Psychological Association or one of its allied publishers.
This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.

related

R 2 = 0.9973

1100

900

700

500
500

700

900

1100

RELATED VOCAL-RESPONSE LATENCY (ms)

Figure 3. Quantile– quantile plots showing the relationship between the latencies in the phonologically related
and unrelated conditions for the vocal responses and gaze shifts in Experiment 1.

ROELOFS

This document is copyrighted by the American Psychological Association or one of its allied publishers.
This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.

360

were recorded while participants named both pictures of the
picture–picture stimuli and manually responded to the arrows. For
example, they said “hammer chisel” in response to a pictured
hammer in green color and a pictured chisel in red (semantically
related) and they said “hammer sandal” in response to a pictured
hammer in green color and a pictured sandal in red (semantically
unrelated). Or they said “circle circus” in response to a pictured
circle in green and a pictured circus in red (phonologically related)
and they said “circle table” in response to a pictured circle in green
and a pictured table in red (phonologically unrelated). The utterances had to be produced fluently, without a pause between the
two names. If the phonological effects obtained in Experiment 1
were due to the selection of both picture names, the results from
naming one picture in Experiment 1 should be replicated with the
naming of both pictures in Experiment 2.

Method
The method was the same as in Experiment 1, except that the
participants named both pictures on each trial, first the green one
and then the red one. The experiment was run with 18 new
participants.

Results and Discussion
Table 2 gives for each distractor condition the mean latencies,
their standard deviations, and the error percentages for the vocal
responses and gaze shifts. The table shows that the latencies of the
vocal responses were slightly longer in the semantically related
than unrelated condition (17 ms), whereas those of the gaze shifts
did not differ (0 ms). The latencies also did not differ much
between the phonologically related and unrelated conditions for the
vocal responding and gaze shifting (respectively, ⫺7 and ⫺11 ms).
Vocal responses. The statistical analysis of the vocal response
latencies yielded no effect of relation, F1(1, 17) ⬍ 1, MSE ⫽
2,268, p ⫽ .62; F2(1, 38) ⬍ 1, MSE ⫽ 2,640, p ⫽ .74, but there
was an effect of type, F1(1, 17) ⫽ 18.57, MSE ⫽ 2,039, p ⫽ .001;
F2(1, 38) ⫽ 4.36, MSE ⫽ 9,033, p ⫽ .04. Type and relation did not
interact, F1(1, 17) ⫽ 1.53, MSE ⫽ 2,313, p ⫽ .23; F2(1, 38) ⫽
1.06, MSE ⫽ 2,640, p ⫽ .31. Planned comparisons between the
related and unrelated conditions within the semantic and phonological conditions separately confirmed that there were no semantic and phonological effects, respectively, t1(17) ⫽ 1.26,
p ⫽ .23; t2(19) ⫽ 1.24, p ⫽ .23, and t1(17) ⫽ 0.52, p ⫽ .61;
t2(19) ⫽ 0.41, p ⫽ .68. There were no effects in the analysis of
the error rates (all ps ⬎ .40).
Table 2
Mean Latencies (ms), Standard Deviations (SD), and Error
Percentages (E%) per Type and Relation for the Vocal
Responses and Gaze Shifts in Experiment 2
Vocal

Gaze

Type

Relation

M

SD

E%

M

SD

Semantic

Related
Unrelated
Related
Unrelated

978
962
922
928

312
313
286
287

4.7
3.6
3.8
4.0

1,431
1,431
1,379
1,390

320
321
299
307

Phonological

Gaze shifts. The statistical analysis of the gaze shift latencies
yielded no effect of relation, F1(1, 17) ⬍ 1, MSE ⫽ 10,018, p ⫽
.83; F2(1, 38) ⬍ 1, MSE ⫽ 10,626, p ⫽ .84, and also no reliable
effect of type, F1(1, 17) ⫽ 8.11, MSE ⫽ 4,812, p ⫽ .01; F2(1,
38) ⫽ 2.06, MSE ⫽ 24,997, p ⫽ .16. Type and relation did not
interact, F1(1, 17) ⬍ 1, MSE ⫽ 2,684, p ⫽ .65; F2(1, 38) ⬍ 1,
MSE ⫽ 10,626, p ⫽ .73. Planned comparisons between the related
and unrelated conditions within the semantic and phonological
conditions separately showed that there were no semantic and
phonological effects, respectively, t1(17) ⫽ 0.00, p ⫽ .99; t2(19) ⫽
0.10, p ⫽ .91, and t1(17) ⫽ 0.39, p ⫽ .70; t2(19) ⫽ 0.35, p ⫽ .73.
Figure 4 shows that the phonological effect was absent throughout the entire latency range for the gaze shifting and vocal responding. Statistical analysis revealed that there was no interaction
of relation and decile for the gaze shifts, F(9, 153) ⫽ 0.19, MSE ⫽
10,814, p ⫽ .95, and also none for the vocal responses, F(9,
153) ⫽ 1.15, MSE ⫽ 2,958, p ⫽ .33. Thus, the absence of
phonological effects is a robust phenomenon, and it does not
depend on latency.
To summarize, the experiment yielded no semantic and phonological relatedness effects on the latencies of naming and gaze
shifting. If the phonological effects in Experiment 1 were due to
the selection of the names of both the green and the red pictures,
the results from naming one picture in Experiment 1 should be
replicated with the naming of both pictures in Experiment 2. This
was not the case, which suggests that the effects of Experiment 1
did not arise because of selecting the names of both pictures.
This raises the question of why semantic and phonological
effects were obtained in naming one of the two pictures (Experiment 1), whereas no such effects were obtained in naming both
pictures (Experiment 2). Elsewhere (Levelt et al., 1999; Roelofs,
1992, 1997, 2003), it was argued that effects of distractor words in
picture naming reflect not only the activation flow within the word
production network but also the attentional weighting of node
activations in selecting a node (cf. Bundesen, 1990, for visual
attention). Whether the outcome is interference or facilitation may
depend on the task and experimental context. The findings from
Experiments 1 and 2 suggest that the outcome for picture–picture
stimuli depends on whether one or two pictures have to be named.
When both pictures have to be named (the task in Experiment 2),
both picture names have to be planned. This may make the related
red picture name a stronger competitor for the green picture name
than when only the green picture name has to be planned (the task
in Experiment 1) and the red one can be ignored. The larger
attentional weight assigned to the picture in red in naming both
pictures may counteract its facilitatory effect on the naming of the
picture in green. The net result may be a null effect, as empirically
observed.
Whereas the gaze shifts were initiated, on average, 145 ms
before the onset of articulation in Experiment 1, they happened, on
average, 450 ms after articulation onset in Experiment 2. This
difference in timing can be explained by assuming that gaze shift
latencies reflected the phonological planning of the whole utterance referring to the picture–picture stimulus, whereas speech
onset latencies did not. The utterance included the names of both
pictures in Experiment 2 (e.g., “hammer chisel”), but only the
name of the green picture in Experiment 1 (e.g., “hammer”).
Levelt and Meyer (2000) and Korvorst et al. (2006) observed that
gaze shift latencies may reflect the phonological length of the

ACTIVATION FLOW IN SPOKEN WORD PLANNING

361

RELATION

CUMULATIVE RELATIVE FREQUENCY

This document is copyrighted by the American Psychological Association or one of its allied publishers.
This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.

related

unrelated

1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
800

1200

1600

2000

GAZE SHIFT LATENCY (ms)

2400

600

800 1000 1200 1400

VOCAL RESPONSE LATENCY (ms)

Figure 4. Vincentized cumulative distribution curves for the vocal responses and gaze shifts in the phonologically related and unrelated conditions of Experiment 2.

utterance even when vocal response latencies do not. For example,
Levelt and Meyer instructed their participants to describe colored
left and right objects (e.g., a big red scooter and a ball) in a simple
or in a complex way. Participants either had to respond with “the
scooter and the ball” or “the big red scooter and the ball.” The gaze
shift latencies for the left stimulus (the scooter) were much shorter
for the simple utterances than for the complex utterances. However, the vocal response latencies did not differ between the two
utterance types. Furthermore, the shift of gaze to the right stimulus
was initiated before articulation onset for the simple utterances, but
after articulation onset for the complex utterances, similar to what
was observed in the present Experiments 1 and 2. This suggests
that the shift of attention and gaze, but not the onset of articulation,
is triggered by the completion of phonological encoding of the
utterance referring to the left stimulus.
Whereas semantic and phonological effects were absent in the
present experiment, Freedman, Martin, and Biegler (2004) observed semantic effects in a double-picture naming task used to
study the role of short-term memory in noun phrase production.
There are several methodological differences between the experiments, which may have yielded the difference in effects. First,
whereas the two pictures were superimposed in the present experiment, they were presented side by side in the experiment of
Freedman et al. Second, whereas semantically related and unrelated trials were randomly intermixed in the present experiments,
the related and unrelated conditions were presented in different
blocks of trials by Freedman et al. Third, whereas the participants
produced two nouns in the present experiments, they produced
conjoined noun phrases (i.e., the two nouns were connected by the
word “and”) in the study of Freedman et al. Fourth, whereas the
pictures remained on the screen until the onset of the manual
response to the arrows in the present experiment, the pictures
disappeared from the screen as soon as the participants began the
utterance in the experiment of Freedman et al. The latter forced the
participants to attend to both pictured objects before speech onset,

which allowed Freedman et al. to study the role of short-term
memory in producing the noun phrases. It seems plausible to
assume that the need to use short-term memory in the experiment
of Freedman et al., but not in the present experiment, is responsible
for the difference in semantic effect between experiments.

Experiment 3
Picture distractors yielded semantic and phonological effects in
Experiment 1 but no such effects in Experiment 2, supporting the
cascade view. The literature indicates, however, that there is no
effect of picture distractors on word reading (e.g., M. O. Glaser &
Glaser, 1982; W. R. Glaser & Düngelhoff, 1984; W. R. Glaser &
Glaser, 1989; Roelofs, 2003, 2006a, 2006b; Smith & Magee,
1980). The absence of an effect of pictures on word reading
suggests that the amount of activation that spreads from concepts
to word forms is limited (Roelofs, 2003). The picture–word asymmetry in effects between picture naming and word reading does
not seem to be due to the relative speed of processing of pictures
and words per se. Words are typically named faster than the
corresponding pictures, namely some 100 –200 ms (e.g., MacLeod,
1991; Roelofs, 2003). However, when one compensates for the
slower processing of pictures by presenting them in advance of the
words to be named (e.g., 300 or 400 ms), still no interference on
word reading is observed (W. R. Glaser & Düngelhoff, 1984). A
similar asymmetry is obtained between naming colors and reading
their names in the color–word Stroop task (Stroop, 1935; see
MacLeod, 1991, for a review) and also between color naming and
spoken color–word naming (Roelofs, 2005). Again, an effect of
distractor color is absent even when the colors are preexposed to
compensate for the difference in processing speed between colors
and words (M. O. Glaser & Glaser, 1982; Roelofs, 2005). This
suggests that the asymmetry between naming pictures and colors,
on the one hand, and naming written or spoken words, on the other,
is due to an architectural difference (i.e., a byproduct of network

ROELOFS

362

This document is copyrighted by the American Psychological Association or one of its allied publishers.
This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.

distance as illustrated in Figure 1, see Roelofs, 2003, 2005) rather
than a difference in relative speed of processing.
Experiment 3 investigated the impact of picture distractors on
word reading using picture–word versions of the stimuli used in
Experiments 1 and 2. The pictures were in red and the words in
green or vice versa. Participants named the picture or word of the
picture–word stimuli depending on whether the picture or word
was presented in green, which varied randomly from trial to trial.
If the effects of picture distractors obtained in Experiment 1 are
absent in word reading, this would corroborate the available evidence that the amount of activation that spreads from concepts to
word forms is limited. As in the previous experiments, both vocal
response latencies and eye movements were recorded.

Method
The method was the same as in Experiment 1, except that
picture–word stimuli were used. There were 20 picture–word pairs
per condition in each task, yielding 160 trials per participant.
Participants named the picture or the word of the picture–word
stimuli depending on whether the picture or the word was presented in green, which varied randomly from trial to trial. The
distractor words were presented in 36-point lowercase Arial font.
On average, the words subtended 5.2° horizontally and 1.3° vertically. The experiment was run with 14 new participants.

Results and Discussion
Table 3 gives for each task and distractor condition the mean
latencies, their standard deviations, and the error percentages for
the vocal responses and gaze shifts. The table shows that the
latencies of picture naming and gaze shifting were longer in the
semantically related than unrelated condition (respectively, 33 and
41 ms for the vocal responses and gazes). Also, the latencies were
longer in the phonologically related than unrelated condition for
both picture naming and gaze shifting (respectively, 38 and 53
ms). However, the latencies for word reading and gaze shifting
were similar in the semantically related and unrelated conditions

Table 3
Mean Latencies (ms), Standard Deviations (SD), and Error
Percentages (E%) per Task, Type, and Relation for the Vocal
Responses and Gaze Shifts in Experiment 3
Vocal
Type

Relation

M

SD

Gaze
E%

M

SD

1.8
3.2
2.1
2.1

844
803
802
749

174
150
171
133

1.1
0.4
0.4
0.4

581
584
613
603

132
116
130
134

Picture naming
Semantic
Phonological

Related
Unrelated
Related
Unrelated

947
914
884
846

267
263
268
235

Word reading
Semantic
Phonological

Related
Unrelated
Related
Unrelated

680
677
688
691

169
203
173
191

(respectively, 3 and ⫺3 ms difference). Also, the latencies for
word reading and gaze shifting were similar in the phonologically
related and unrelated conditions (respectively, ⫺3 and 10 ms
difference). Thus, there were no differences among conditions for
word reading.
Vocal responses. The statistical analysis of the vocal response
latencies yielded main effects of task, F1(1, 13) ⫽ 344.52, MSE ⫽
3,732, p ⫽ .001; F2(1, 76) ⫽ 260.54, MSE ⫽ 7,023, p ⫽ .001,
type, F1(1, 13) ⫽ 6.51, MSE ⫽ 3,176, p ⫽ .02; F2(1, 76) ⫽ 4.15,
MSE ⫽ 7,023, p ⫽ .04, and relation, F1(1, 13) ⫽ 5.92, MSE ⫽
1,537, p ⫽ .03; F2(1, 76) ⫽ 3.53, MSE ⫽ 3,071, p ⫽ .06.
Moreover, there were interactions of task and type, F1(1, 13) ⫽
60.80, MSE ⫽ 675, p ⫽ .001; F2(1, 76) ⫽ 8.15, MSE ⫽ 7,023, p ⫽
.006, task and relation, F1(1, 13) ⫽ 7.11, MSE ⫽ 1,234, p ⫽ .02;
F2(1, 76) ⫽ 3.72, MSE ⫽ 3,071, p ⫽ .06, but not of type and
relation, F1(1, 13) ⬍ 1, MSE ⫽ 2,509, p ⫽ .89; F2(1, 76) ⬍ 1,
MSE ⫽ 3,071, p ⫽ .91. For the picture naming latencies, there
were effects of type, F1(1, 13) ⫽ 29.56, MSE ⫽ 2,029, p ⬍ .001;
F2(1, 38) ⫽ 8.15, MSE ⫽ 10,318, p ⫽ .007, and relation, F1(1,
13) ⫽ 10.63, MSE ⫽ 1,680, p ⫽ .006; F2(1, 38) ⫽ 6.14, MSE ⫽
3,623, p ⫽ .02. Type and relation did not interact, F1(1, 13) ⬍ 1,
MSE ⫽ 1,758, p ⫽ .97; F2(1, 38) ⬍ 1, MSE ⫽ 3,623, p ⫽ .93.
Planned comparisons between the related and unrelated conditions
within the semantic and phonological conditions separately
showed that there were semantic and phonological effects in the
analysis by participants, respectively, t1(13) ⫽ 2.39, p ⫽ .03;
t2(19) ⫽ 1.59, p ⫽ .13, and t1(13) ⫽ 2.18, p ⫽ .05; t2(19) ⫽ 1.94,
p ⫽ .07. Again, whereas the main effect of relation was significant
both by participants and by items, the relatedness effects within the
semantic and phonological conditions separately reached significance in the analysis by participants only, presumably because
dividing the items by type reduced the power of the analysis by
items. For the word reading latencies, there were no effects of type
and relation, and type and relation did not interact (all Fs ⬍ 1).
Planned comparisons between the related and unrelated conditions
within the semantic and phonological conditions separately
showed that there were no semantic and phonological effects,
respectively, t1(13) ⫽ 0.22, p ⫽ .83; t2(19) ⫽ 0.14, p ⫽ .88, and
t1(13) ⫽ 0.20, p ⫽ .84; t2(19) ⫽ 0.24, p ⫽ .81. To conclude, there
were effects in picture naming but not in word reading. The error
rates differed between tasks, F1(1, 13) ⫽ 10.48, p ⫽ .006; F2(1,
76) ⫽ 15.52, p ⫽ .001, showing that more errors were made in the
picture naming than in the word reading task. Given that more
errors were made in the slower task, there is no evidence for a
speed–accuracy trade-off. There were no other error effects (all
ps ⬎ .15).
Gaze shifts. The statistical analysis of the gaze shift latencies
yielded main effects of task, F1(1, 13) ⫽ 172.86, MSE ⫽ 6,750,
p ⫽ .001; F2(1, 76) ⫽ 171.52, MSE ⫽ 9,780, p ⫽ .001, relation,
F1(1, 13) ⫽ 5.37, MSE ⫽ 3,257, p ⫽ .04; F2(1, 76) ⫽ 5.45,
MSE ⫽ 4,381, p ⫽ .02, but not of type, F1(1, 13) ⫽ 1.01, MSE ⫽
3,459, p ⫽ .33; F2(1, 76) ⬍ 1, MSE ⫽ 9,780, p ⫽ .44. Moreover,
there were interactions of task and type, F1(1, 13) ⫽ 17.42, MSE ⫽
2,144, p ⫽ .001; F2(1, 76) ⫽ 5.55, MSE ⫽ 9,780, p ⫽ .021, task
and relation, F1(1, 13) ⫽ 7.66, MSE ⫽ 1,731, p ⫽ .02; F2(1, 76) ⫽
4.54, MSE ⫽ 4,381, p ⫽ .04, but not of type and relation, F1(1,
13) ⬍ 1, MSE ⫽ 2,061, p ⫽ .46; F2(1, 76) ⬍ 1, MSE ⫽ 4,381, p ⫽
.59. For picture naming, there was an effect of type in the byparticipants analysis, F1(1, 13) ⫽ 11.57, MSE ⫽ 2,751, p ⫽ .005;

This document is copyrighted by the American Psychological Association or one of its allied publishers.
This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.

ACTIVATION FLOW IN SPOKEN WORD PLANNING

F2(1, 38) ⫽ 3.03, MSE ⫽ 15,997, p ⫽ .09, and there was an effect
of relation, F1(1, 13) ⫽ 10.83, MSE ⫽ 2,826, p ⫽ .006; F2(1,
38) ⫽ 7.22, MSE ⫽ 6,048, p ⫽ .011. Type and relation did not
interact, F1(1, 13) ⬍ 1, MSE ⫽ 2,331, p ⫽ .63; F2(1, 38) ⬍ 1,
MSE ⫽ 6,048, p ⫽ .80. Planned comparisons between the related
and unrelated conditions within the semantic and phonological
conditions separately showed that there was a semantic effect in
the analysis by participants, t1(13) ⫽ 2.76, p ⫽ .02; t2(19) ⫽ 1.59,
p ⫽ .13, and a phonological effect, t1(13) ⫽ 2.32, p ⫽ .04;
t2(19) ⫽ 2.29, p ⫽ .03. For word reading, there were no effects of
type, F1(1, 13) ⫽ 3.16, MSE ⫽ 2,851, p ⫽ .10; F2(1, 38) ⫽ 3.31,
MSE ⫽ 3,664, p ⫽ .08, or relation (both Fs ⬍ 1), and type and
relation did not interact (both Fs ⬍ 1). Planned comparisons
between the related and unrelated conditions within the semantic
and phonological conditions separately showed that there were no
semantic and phonological effects, respectively, t1(13) ⫽ 0.26,
p ⫽ .80; t2(19) ⫽ 0.26, p ⫽ .80, and t1(13) ⫽ 0.52, p ⫽ .61;
t2(19) ⫽ 0.57, p ⫽ .58. Thus, there were effects in picture naming
but not in word reading.
Figure 5 shows the distributional plots for the latencies of the
gaze shifts and vocal responses of word reading and picture
naming in the phonologically related and unrelated conditions.
The left panel shows that the phonological effect on the gaze
shifts was absent throughout the latency distribution for word
reading, whereas the effect was present across the entire latency
range except for the short latencies in picture naming. This
suggests that when the gaze shifts occur early, before the onset
of phonological encoding, phonological effects are absent. Statistical analysis revealed that there was an interaction of relation and decile for picture naming, F(9, 117) ⫽ 5.82, MSE ⫽
4,862, p ⫽ .001, but there was no reliable interaction for word
reading, F(9, 117) ⫽ 1.74, MSE ⫽ 1,731, p ⫽ .09. The right
panel shows that the phonological effect on the vocal responses
was also absent throughout the latency distribution for word

363

reading, whereas the effect was present throughout the latency
range for picture naming. Statistical analysis revealed that there
were no interactions of relation and decile for picture naming,
F(9, 117) ⫽ 1.87, MSE ⫽ 6,012, p ⫽ .06, and word reading,
F(9, 117) ⫽ 0.50, MSE ⫽ 3,065, p ⫽ .87. Figure 5 also reveals
that for both the gaze shifts and the vocal responses, the
asymmetry in effects between picture naming and word reading
existed even in the overlapping latency ranges, namely between
460 and 1,000 ms for gaze shifting and between 540 and 1,000
ms for vocal responding. The presence of the asymmetry in the
absence of a latency difference provides evidence that the
picture–word asymmetry is a byproduct of network distance
(Roelofs, 2003, 2005) rather than being caused by a difference
in relative speed of processing.
To summarize, word distractors yielded semantic and phonological effects in picture naming, whereas picture distractors
yielded no effect on word reading, regardless of latency. The
asymmetry in effects was obtained in the latencies of both vocal
responding and gaze shifting. The picture–word asymmetry
suggests that the amount of activation that cascades from concepts to word forms is limited and attention dependent (Roelofs,
2003).
Whereas phonologically related distractor words usually speed
up picture naming compared to unrelated words (e.g., Damian &
Martin, 1999; Schriefers et al., 1990), they yielded phonological
interference in the present experiment. Thus, the fact that the
distractor word affords the other task in the experiment (oral
reading) does influence the nature of the effect it has on picture
naming. The phonological interference effect suggests that the
phonologically related distractor words were stronger competitors
in the present experiment than they normally are (i.e., when they
are not the targets of the other task in an experiment), turning the
usual phonological facilitation into interference.

Figure 5. Vincentized cumulative distribution curves for the vocal responses and gaze shifts of word reading
and picture naming in the phonologically related and unrelated conditions of Experiment 3.

ROELOFS

364

This document is copyrighted by the American Psychological Association or one of its allied publishers.
This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.

100
80
Interference

60

Facilitation

Following Levelt et al. (1999) and Roelofs (1992, 2003), the
difference in the direction of the distractor effects between experiments (facilitation in Experiment 1, no effect in Experiment 2, and
interference in Experiment 3) was explained as a difference in
trade-off between facilitation and interference in word planning,
depending on the task situation. Here, I report the results of
WEAVER⫹⫹ simulations of the phonological effect that demonstrate the utility of this approach. The procedures in simulating the
phonological effects were identical to the procedures in the simulations reported by Roelofs (1997), except that the effect of
picture rather than spoken word distractors was examined in the
present simulations. The phonological effect of picture distractors
was simulated by giving input activation to the morpheme nodes of
both the target and the distractor picture names. For example, the
target picture name was Dutch hamer (English hammer), and the
name of the distractor picture was phonologically related (havik,
English hawk) or phonologically unrelated (bezem, English
broom). To simulate weak cascading of activation, the input to the
distractor morpheme (i.e., ⬍havik⬎ or ⬍bezem⬎) was only 5% of
the input to the target (i.e., ⬍hamer⬎). This yielded a basic
phonological facilitation effect of 27 ms in the simulations. The
real effect in Experiment 1 was 29 ms. Roelofs (2003) showed that
WEAVER⫹⫹ accounts for the picture–word asymmetry if the
spreading rate between lemmas and word forms is lower than 40%
of the spreading rate within the form network. Thus, a weakly
cascading version of WEAVER⫹⫹ accounts for the picture–
picture phonological facilitation effect, on the one hand, and the
picture–word asymmetry, on the other.
In WEAVER⫹⫹, phonological encoding is followed by the
selection of syllable motor programs from a mental syllabary.
Based on the constructed phonological word representation, corresponding syllable motor programs are isolated in the syllabary.
The probability of actual selection of a syllable program node at a
particular moment in time is given by the ratio of the activation of
the target syllable program and the sum of the activations of all
stored syllable motor programs (Roelofs, 1997). The attentional
weighting of the activations in the ratio may depend on the task
situation (Levelt et al., 1999). The outcomes of Experiment 3
suggest that phonologically related distractors are stronger competitors in a task-mixing situation than in a normal picture–word
interference experiment with only one task (i.e., picture naming).
The confidence of the system in an isolated target syllable may be
lower when tasks are mixed than when they are blocked. The
negative effect of phonological overlap in a task-mixing situation
was simulated by reducing the weight of the target syllable in the
selection ratio, representing lower confidence in the target. For
example, a weight of 0.8 implied that the model was less likely
than normal (with a weight of 1.0) to select the target syllable
because it was part of the distractor name. Figure 6 shows the
effect of the attentional weight on the phonological facilitation
effect. When the weight is still large (e.g., 0.8 or 0.6), there is only
a small reduction in the size of the phonological facilitation effect.
However, with smaller weights (e.g., 0.4 or 0.2), the phonological
facilitation effect (observed in Experiment 1) turns into phonological interference (observed in Experiment 3).
A similar explanation may be given for the difference in direction of semantic effects. Whereas Damian and Bowers (2003)

PHONOLOGICAL EFFECT (ms)

WEAVER⫹⫹ Simulations

40
20
0
-20
-40
1.0

0.8

0.6

0.4

0.2

ATTENTIONAL WEIGHT
Figure 6. The phonological effect as a function of the attentional weight
in WEAVER⫹⫹ simulations.

obtained no semantic effect of picture distractors on picture naming, W. R. Glaser and Glaser (1989) obtained semantic interference, and La Heij et al. (2003) obtained semantic interference or
facilitation depending on the ease of target selection. Thus, it
seems that if separating the target and distractor is easy, the
system’s confidence in the isolated lemma is high, and the lemma
receives a large weight in the selection ratio relative to other
lemmas. Consequently, semantic facilitation appears (cf. Figure 6).
In contrast, if separating target and distractor is difficult, the
system’s confidence in the isolated lemma is lower, and the lemma
receives a smaller weight in the selection ratio. As a consequence,
semantic interference occurs (cf. Figure 6). Roelofs (1992) demonstrated the utility of such an approach through computer simulations.
To summarize, the simulations revealed that a weakly cascading
version of WEAVER⫹⫹ can account for the phonological effect
in the picture–picture task, on the one hand, and the picture–word
asymmetry, on the other. Moreover, the simulations showed that
the differences in direction of the phonological effects (facilitation
in Experiment 1, no effect in Experiment 2, and interference in
Experiment 3) may be explained as differences in trade-off between facilitation and interference, depending on the task situation
(cf. Levelt et al., 1999). A similar account may be given for the
difference in direction of the semantic effects (cf. Roelofs, 1992).
Clearly, the proposed account of the variation in direction of
effects is tentative and needs to be examined further in future
research. However, it is important to note that the difference in
direction of effects does not really affect the main conclusions. The
presence of a phonological effect in the picture–picture task in
Experiment 1 suggests that context pictures activate the phonological forms of their names. This conclusion holds regardless of
whether the effect is one of facilitation or interference. The phonological effect per se supports the cascade view. Moreover, the
absence of an effect of pictures on word reading in Experiment 3
suggests that the amount of activation that spreads from concepts
to phonological forms is limited and task dependent. This conclusion holds regardless of whether the effects of the words in naming
the pictures concern facilitation or interference.

ACTIVATION FLOW IN SPOKEN WORD PLANNING

This document is copyrighted by the American Psychological Association or one of its allied publishers.
This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.

General Discussion
The present article reported three experiments that examined the
relative merits of the continuous and discrete views on the activation flow within the word production system. Experiment 1 was a
replication and extension of Morsella and Miozzo (2002) and
Navarrete and Costa (2005), testing for an effect of phonological
relatedness of two pictures with the use of eye tracking. Different
from Morsella and Miozzo, all pictures occurred both as targets
and distractors. This manipulation served to optimize a comparison
between Experiment 1 and Experiment 2, where both pictures had
to be named and therefore both were part of the response set.
Experiment 1 replicated the effect of phonological relatedness
obtained by Morsella and Miozzo not only for the vocal responses
but also for the gaze shifts. The effect of phonological relatedness
of two pictures was obtained in the context of a semantic effect,
which was clearly present in the gaze shift latencies.
Distractor pictures that are part of the response set may be more
salient than distractor pictures that are not. Moreover, naming a
picture may strengthen the stimulus–response connection. Presenting a previously named picture as distractor may lead to more
activation of the distractor’s name than presenting a distractor
picture that has not been named before (e.g., Waszak, Hommel, &
Allport, 2003). It may be argued that the phonological facilitation
effect is due to the fact that the distractor pictures were possible
responses in the present experiments. However, this cannot be the
case, because Morsella and Miozzo (2002) and Navarrete and
Costa (2005) obtained the phonological facilitation effect for distractor pictures that were not targets in the experiment. Similarly,
A. S. Meyer and Damian (2007) investigated effects of phonological begin- and end-overlap between two pictures, as well as
potential effects of a familiarization phase. Both types of overlap
yielded comparable phonological facilitation effects, and whether
participants had been familiarized with the pictures prior to the
experimental session did not really matter. The phonological effect
did not change systematically over six repetitions of the materials.
Moreover, a greater salience or stimulus–response connection
strength of distractor pictures could only lead to phonological
activation of their names in a discrete system if the greater salience
or strength leads to the selection of the concept (Bloem & La Heij,
2003) or the lemma (Levelt et al., 1999) of the distractor’s name.
Selection is goal dependent in the model of word planning proposed by Levelt et al. (1999). However, Experiment 2 showed that
when the goal explicitly includes the selection of the name of the
picture in red, this still does not yield phonological facilitation.
Phonological effects in the picture–picture task do not necessarily support a continuous spread of activation within the word
production system. The effects may also be obtained as a result of
misselection. Levelt et al. (1999) suggested that in case of synonyms, speakers mistakenly select the names of both pictures.
Bloem et al. (2004) argued that the participants in the experiment
of Morsella and Miozzo (2002) mistakenly selected the wrong
picture name on some of the trials. This would explain the phonological effect. However, distributional analyses in Experiment 1
revealed that the phonological effect increased linearly with latency, for both the vocal responses and the gaze shifts. The
linearity excludes that the effect occurred on some of the trials
(i.e., the slow ones) only. This suggests that the phonological
effect does not arise because of lapses of attention. Still, the

365

findings on the latency distributions are compatible with the idea
that selecting the names of both pictures is the way that participants deal with the selective attention problem in the picture–
picture task. Experiment 2 examined the effect of planning the
names of both pictures. On each trial, participants named both
pictures, first the green one and then the red one. If the phonological effects in Experiment 1 were due to the selection of the names
of both the green and the red pictures, the results from naming one
picture in Experiment 1 should be replicated with the naming of
both pictures in Experiment 2. This was not the case, which
suggests that the effects in Experiment 1 did not arise because of
a special planning strategy adopted to deal with the overlapping
pictures.
Picture distractors yielded semantic and phonological facilitation effects in Experiment 1 but no such effects in Experiment 2,
supporting the continuous view. The literature suggests, however,
that the amount of activation that cascades from concepts to word
forms is restricted, because there is no effect of picture distractors
on word reading. Experiment 3 examined the influence of picture
distractors on word reading using picture–word versions of the
stimuli used in Experiments 1 and 2. Participants named the
picture or word of picture–word stimuli depending on whether the
picture or word was presented in green, which varied randomly
from trial to trial. The experiment showed that word distractors
yielded semantic and phonological effects in picture naming, but
picture distractors yielded no effect on word reading. The picture–
word asymmetry suggests that the spread of activation from concepts to word forms is limited and attention dependent.
The attention dependence of the flow of activation also explains
why there is a phonological facilitation effect in the picture–
picture task, whereas there is no easily detectable activation of the
phonological form of semantic competitors of a picture name, as
observed for picture naming in the dual-task paradigm used by
Levelt et al. (1991), Peterson and Savoy (1998), and Roelofs
(2003). A major difference between the picture–picture task and
picture naming in a dual-task situation is that the competitor that
yields phonological activation is explicitly presented as a picture in
the picture–picture task but not in the dual-task situation. In
performing the picture–picture task, both the target and the distractor picture are probably given attention as part of the process of
separating them (cf. Allport et al., 1985; MacLeod, 1998). This
would mean that the competitor that yields phonological activation
is more activated in the picture–picture task than in picture naming
in the dual-task paradigm, explaining the phonological effect. As
indicated, a difference in selective attention also explains why
picture distractors yield a phonological effect in picture naming,
whereas they have no effect at all in word reading. Only when
participants attentionally enhance the activation of the picture
name do pictures have an effect on word reading, as observed by
Peterson and Savoy, and as observed by Roelofs (2003) for the
color–word Stroop task. These differences among studies suggest
that the amount of activation that cascades through the system is
limited.
The evidence from the present experiments for limited cascading agrees with the observation of Roelofs, Özdemir, and Levelt
(2007) that passive picture viewing does not lead to significant
phonological activation. Participants were shown pictures while
hearing a tone or a spoken word presented 600 ms after picture
onset. When a spoken word was presented, participants indicated

ROELOFS

This document is copyrighted by the American Psychological Association or one of its allied publishers.
This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.

366

whether it contained a prespecified phoneme. When the tone was
presented, they indicated whether the picture name contained the
phoneme (one experiment), or they named the picture (another
experiment). Phoneme monitoring latencies for the spoken words
were shorter when the picture name contained the prespecified
phoneme compared to when it did not. However, no priming of
phoneme monitoring was obtained (in another experiment) when
the pictures required no response but were only passively viewed,
regardless of monitoring latency. These results suggest that attentional enhancements are a precondition for obtaining phonological
activation from pictures.
What do the present findings imply for existing theories of
lexical access in word production? Levelt et al. (1999) argued that
perceived objects continuously activate their concepts and lemmas,
whereas the morphemes, phonemes, and syllable motor programs
of the object names are activated only when a speaker has the goal
of naming the objects. Dell (1986) argued that all word forms
corresponding to the activated concepts and lemmas become continuously activated. And Altmann and Davidson (2001) and Bloem
and La Heij (2003) argued that although objects activate their
concepts and related ones, the lemmas, morphemes, phonemes,
and motor programs of the object names are only activated when
a speaker has the goal of naming the objects. The phonological
facilitation effect from distractor pictures in Experiment 1 and the
absence of the effect in Experiment 2 challenges the claim of
Bloem and La Heij that only selected concepts activate their
lemmas and forms, and it challenges the claim of Levelt et al.
(1999) that only selected lemmas activate their word forms. The
phonological facilitation effect from the picture–picture task supports the claim of Dell that activation spreads continuously from
concepts to lemmas and from lemmas to forms. However, the
evidence from word reading in Experiment 3 suggests that the
amount of activation from pictures arriving at the word forms is
limited and task dependent (Roelofs, 2003). Whereas Levelt et al.
(1999) assumed that the transition of activation from lemmas to
word forms occurs in a discrete step, the present findings suggest
that the activation is weakly cascading. That is, activation cascades
from lemmas to forms, but the amount of activation is limited and
task dependent.
To conclude, the results from the present picture–picture and
picture–word interference experiments support the cascade view
and demand a change of discrete models like WEAVER⫹⫹. At
the same time, the absence of an effect of distractor pictures on
word reading suggests that the amount of activation that spreads
continuously from concepts to phonological forms is limited.
Computer simulations using a weakly cascading version of
WEAVER⫹⫹ showed that the model accounts for the phonological effect in the picture–picture task, on the one hand, and for the
picture–word asymmetry, on the other. Moreover, the simulations
showed that the differences between experiments in the direction
of the phonological effects may be explained as differences in the
trade-off between interference and facilitation in word-form encoding, depending on the task situation.

References
Allport, D. A., Tipper, S. P., & Chmiel, N. R. J. (1985). Perceptual
integration and postcategorical filtering. In M. I. Posner & O. S. M.
Marin (Eds.), Attention and performance XI (pp. 107–132). London:
Erlbaum.

Altmann, E. M., & Davidson, D. J. (2001). An integrative approach to
Stroop: Combining a language model and a unified cognitive theory.
Proceedings of the 23rd meeting of the Cognitive Science Society (pp.
21–26). Hillsdale, NJ: Erlbaum.
Bloem, I., & La Heij, W. (2003). Semantic facilitation and semantic
interference in word translation: Implications for models of lexical
access in language production. Journal of Memory and Language, 48,
468 – 488.
Bloem, I., Van den Boogaard, S., & La Heij, W. (2004). Semantic facilitation and semantic interference in language production: Further evidence for the conceptual selection model of lexical access. Journal of
Memory and Language, 51, 307–323.
Bundesen, C. (1990). A theory of visual attention. Psychological Review,
97, 523–547.
Cutting, J. C., & Ferreira, V. S. (1999). Semantic and phonological information flow in the production lexicon. Journal of Experimental Psychology: Learning, Memory, and Cognition, 25, 318 –344.
Damian, M. F., & Bowers, J. S. (2003). Locus of semantic interference in
picture-word interference tasks. Psychonomic Bulletin and Review, 10,
111–117.
Damian, M. F., & Martin, R. C. (1999). Semantic and phonological codes
interact in single word production. Journal of Experimental Psychology:
Learning, Memory, and Cognition, 25, 345–361.
De Jong, R., Liang, C.-C., & Lauber, E. (1994). Conditional and unconditional automaticity: A dual-process model of effects of spatial
stimulus-response correspondence. Journal of Experimental Psychology: Human Perception and Performance, 20, 731–750.
Dell, G. S. (1986). A spreading-activation theory of retrieval in sentence
production. Psychological Review, 93, 283–321.
Dell, G. S., & O’Seaghdha, P. G. (1991). Mediated and convergent lexical
priming in language production: A comment on Levelt et al. Psychological Review, 98, 604 – 614.
Freedman, M. L., Martin, R. C., & Biegler, K. (2004). Semantic relatedness
effects in conjoined noun phrase production: Implications for the role of
short-term memory. Cognitive Neuropsychology, 21, 245–265.
Glaser, M. O., & Glaser, W. R. (1982). Time course analysis of the Stroop
phenomenon. Journal of Experimental Psychology: Human Perception
and Performance, 8, 875– 894.
Glaser, W. R., & Düngelhoff, F.-J. (1984). The time course of picture-word
interference. Journal of Experimental Psychology: Human Perception
and Performance, 10, 640 – 654.
Glaser, W. R., & Glaser, M. O. (1989). Context effects in Stroop-like word
and picture processing. Journal of Experimental Psychology: General,
118, 13– 42.
Griffin, Z. M. (2001). Gaze durations during speech reflect word selection
and phonological encoding. Cognition, 82, B1–B14.
Griffin, Z. M., & Bock, K. (1998). Constraint, word frequency, and levels
of processing in spoken word production. Journal of Memory and
Language, 38, 313–338.
Jescheniak, J. D., Hahne, A., & Schriefers, H. (2003). Information flow in
the mental lexicon during speech planning: Evidence from event-related
brain potentials. Cognitive Brain Research, 15, 261–276.
Jescheniak, J. D., & Levelt, W. J. M. (1994). Word frequency effects in
speech production: Retrieval of syntactic information and phonological
form. Journal of Experimental Psychology: Learning, Memory, and
Cognition, 20, 824 – 843.
Korvorst, M., Roelofs, A., & Levelt, W. J. M. (2006). Incrementality in
naming and reading complex numerals: Evidence from eyetracking.
Quarterly Journal of Experimental Psychology, 59, 296 –311.
LaBerge, D. (1995). Attentional processing: The brain’s art of mindfulness. Cambridge, MA: Harvard University Press.
La Heij, W., Heikoop, K. W., Akerboom, S., & Bloem, I. (2003). Picture
naming in picture context: Semantic interference or semantic facilitation? Psychology Science, 45, 49 – 62.

This document is copyrighted by the American Psychological Association or one of its allied publishers.
This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.

ACTIVATION FLOW IN SPOKEN WORD PLANNING
Levelt, W. J. M., & Meyer, A. S. (2000). Word for word: Multiple lexical
access in speech production. European Journal of Cognitive Psychology,
12, 433– 452.
Levelt, W. J. M., Roelofs, A., & Meyer, A. S. (1999). A theory of lexical
access in speech production. Behavioral and Brain Sciences, 22, 1–38.
Levelt, W. J. M., Schriefers, H., Vorberg, D., Meyer, A. S., Pechmann, T.,
& Havinga, J. (1991). The time course of lexical access in speech
production: A study of picture naming. Psychological Review, 98, 122–
142.
MacLeod, C. M. (1991). Half a century of research on the Stroop effect: An
integrative review. Psychological Bulletin, 109, 163–203.
MacLeod, C. M. (1998). Training on integrated versus separated Stroop
tasks: The progression of interference and facilitation. Memory & Cognition, 26, 201–211.
Meyer, A. S., & Damian, M. F. (2007). Activation of distractor names in
the picture-picture interference paradigm. Memory & Cognition, 35,
494 –503.
Meyer, A. S., Roelofs, A., & Levelt, W. J. M. (2003). Word length effects
in object naming: The role of a response criterion. Journal of Memory
and Language, 48, 131–147.
Meyer, A. S., Sleiderink, A. M., & Levelt, W. J. M. (1998). Viewing and
naming objects. Cognition, 66, B25–B33.
Meyer, A. S., & Van der Meulen, F. F. (2000). Phonological priming of
picture viewing and picture naming. Psychonomic Bulletin and Review,
7, 314 –319.
Meyer, D. E., Osman, A. M., Irwin, D. E., & Yantis, S. (1988). Modern
mental chronometry. Biological Psychology, 26, 3– 67.
Morsella, E., & Miozzo, M. (2002). Evidence for a cascade model of
lexical access in speech production. Journal of Experimental Psychology: Learning, Memory, and Cognition, 28, 555–563.
Navarrete, E., & Costa, A. (2005). Phonological activation of ignored
pictures: Further evidence for a cascade model of lexical access. Journal
of Memory and Language, 53, 359 –377.
Peterson, R. R., & Savoy, P. (1998). Lexical selection and phonological
encoding during language production: Evidence for cascaded processing. Journal of Experimental Psychology: Learning, Memory, and Cognition, 24, 539 –557.
Posner, M. I., & Dehaene, S. (1994). Attentional networks. Trends in
Neurosciences, 17, 75–79.
Ratcliff, R. (1979). Group reaction time distributions and an analysis of
distribution statistics. Psychological Bulletin, 86, 446 – 461.
Ridderinkhof, K. R. (2002). Activation and suppression in conflict tasks:
Empirical clarification through distributional analyses. In W. Prinz & B.
Hommel (Eds.), Attention and Performance XIX: Common mechanisms
in perception and action (pp. 494 –519). Oxford: Oxford University
Press.

367

Roelofs, A. (1992). A spreading-activation theory of lemma retrieval in
speaking. Cognition, 42, 107–142.
Roelofs, A. (1997). The WEAVER model of word-form encoding in
speech production. Cognition, 64, 249 –284.
Roelofs, A. (1998). Rightward incrementality in encoding simple phrasal
forms in speech production: Verb-particle combinations. Journal of
Experimental Psychology: Learning, Memory, and Cognition, 24, 904 –
921.
Roelofs, A. (2003). Goal-referenced selection of verbal action: Modeling
attentional control in the Stroop task. Psychological Review, 110, 88 –
125.
Roelofs, A. (2005). The visual-auditory color-word Stroop asymmetry and
its time course. Memory & Cognition, 33, 1325–1336.
Roelofs, A. (2006a). Context effects of pictures and words in naming
objects, reading words, and generating simple phrases. Quarterly Journal of Experimental Psychology, 59, 1764 –1784.
Roelofs, A. (2006b). Functional architecture of naming dice, digits, and
number words. Language and Cognitive Processes, 21, 78 –111.
Roelofs, A. (2007). Attention and gaze control in picture naming, word
reading, and word categorizing. Journal of Memory and Language, 57,
232–251.
Roelofs A., Özdemir, R., & Levelt, W. J. M. (2007). Influences of spoken
word planning on speech recognition. Journal of Experimental Psychology: Learning, Memory, and Cognition, 33, 900 –913.
Schriefers, H., Meyer, A., & Levelt, W. J. M. (1990). Exploring the
time-course of lexical access in language production: Picture-word interference studies. Journal of Memory and Language, 29, 86 –102.
Smith, M. C., & Magee, L. E. (1980). Tracing the time course of pictureword processing. Journal of Experimental Psychology: General, 109,
373–392.
Stroop, J. R. (1935). Studies of interference in serial verbal reactions.
Journal of Experimental Psychology, 18, 643– 662.
Thomas, E. A. C., & Ross, B. H. (1980). On appropriate procedures for
combining probability distributions within the same family. Journal of
Mathematical Psychology, 21, 136 –152.
Waszak, F., Hommel, B., & Allport, A. (2003). Task-switching and longterm binding: Role of episodic stimulus-task bindings in task-shift costs.
Cognitive Psychology, 46, 361– 413.
Wilk, M. B., & Gnanadesikan, R. (1968). Probability plotting methods for
the analysis of data. Biometrika, 55, 1–17.
Zhang, J., & Kornblum, S. (1997). Distributional analysis and De Jong,
Liang, and Lauber’s (1994) dual-process model of the Simon effect.
Journal of Experimental Psychology: Human Perception and Performance, 23, 1543–1551.

(Appendix follows)

ROELOFS

368

Appendix

Materials of the Experiments

This document is copyrighted by the American Psychological Association or one of its allied publishers.
This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.

Distractor
Target

Semantically related

Semantically unrelated

schildpad (tortoise)
konijn (rabbit)
vliegtuig (aircraft)
auto (car)
molen (mill)
fabriek (factory)
kanon (cannon)
pistool (pistol)
bureau (desk)
zetel (seat)
beitel (chisel)
hamer (hammer)
sandaal (sandal)
zwemvlies (flipper)
appel (apple)
banaan (banana)
trompet (trumpet)
cello (cello)
vulpen (fountain pen)
potlood (pencil)

konijn
schildpad
auto
vliegtuig
fabriek
molen
pistool
kanon
zetel
bureau
hamer
beitel
zwemvlies
sandaal
banaan
appel
cello
trompet
potlood
vulpen

vliegtuig
auto
schildpad
konijn
pistool
kanon
fabriek
molen
beitel
hamer
bureau
zetel
appel
banaan
sandaal
zwemvlies
vulpen
potlood
trompet
cello

Phonologically related

Phonologically unrelated

bezem (broom)
beker (cup)
wapen (weapon)
waaier (fan)
lepel (spoon)
lelie (lily)
kabel (cable)
kano (canoe)
koning (king)
kogel (bullet)
rugby (rugby)
rugzak (backpack)
tafel (table)
taco (taco)
zebra (zebra)
zegel (seal)
toren (tower)
totem (totem)
circus (circus)
cirkel (circle)
Note.

beker
bezem
waaier
wapen
lelie
lepel
kano
kabel
kogel
koning
rugzak
rugby
taco
tafel
zegel
zebra
token
toren
cirkel
circus

wapen
waaier
bezem
beker
kano
kabel
lelie
lepel
rugby
rugzak
koning
kogel
zebra
zegel
tafel
taco
circus
cirkel
toren
totem

English translations of the Dutch targets and distractors are given in parentheses.

Received June 30, 2006
Revision received October 3, 2007
Accepted October 29, 2007 䡲

